### 2.28 

#### 1.1 TCP/IP网络模型 <a name="1.1-1"></a>

> TCP/IP 模型（全称 Transmission Control Protocol/Internet Protocol，即传输控制协议/互联网协议）是一种网络通信模型，用来描述计算机网络中数据的传输和通信过程。它是互联网的基础，现实中大多数网络协议都基于这个模型构建。

##### 1、为什么要有TCP/IP网络模型？

TCP/IP协议是为了解决计算机之前的通信问题。对于同一种设备上的通讯，可以有多种通信方式，但是在不同设备上的进程间通信，就需要网络通信。而设备时多样性的，要兼容多种设备，就需要协商一套通用的网络协议。

##### 2、TCP/IP协议的层级

分层就是把一个大任务拆成几个小任务，给不同的人去做。

**为什么要把 TCP/IP 分层？**

- 分工明确，降低复杂性
- 各层独立，互不干扰
- 提高灵活性和兼容性
- 方便排查问题
- 复用化和标准化

TCP/IP分成四层：网络接口层、网络层、传输层、应用层

![undefined](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/UDP_encapsulation.svg/1920px-UDP_encapsulation.svg.png)



**应用层**

最上层，用户能直接接触到的就是应用层。负责处理用户能看到的、用到的东西，比如浏览网页、发邮件、看视频。当两个不同的设备的应用需要通信的时候，应用把应用数据传给下一层，也就是传输层。

应用层只需要专注于为用户提供应用功能。应用层的关键协议如下：

- HTTP(超文本传输协议)：输入网址，HTTP负责把网站内容拉回来
- SMTP(简单右键传输协议)：发送邮件
- FTP(文件传输协议)：传文件的协议

应用层不用关心数据如何传输，它是在操作系统中的用户态，传输层及以下则工作在内核态。



**传输层**

应用层的数据包会传给传输层，传输层是为了应用层提供网络支持。

![image-20250227215640454](C:/Users/15251/AppData/Roaming/Typora/typora-user-images/image-20250227215640454.png)

在TCP/IP模型中，传输层主要由两种协议主导：**TCP（传输控制协议）\**和\**UDP（用户数据报协议）**。

 **TCP（Transmission Control Protocol）**：数据包能可靠地传输给对方

- **特点**: 面向连接、可靠的数据传输。
- 功能
  - **建立连接**：通过三次握手确保通信双方准备就绪。
  - **数据可靠性**：提供数据包的排序、重传机制，确保数据无丢失、无重复且按序到达。
  - **流量控制**：通过滑动窗口机制调节发送速率，避免接收方过载。
  - **拥塞控制**：防止网络过载，提升传输效率。
- **应用场景**：适用于需要高可靠性的场景，如网页浏览（HTTP/HTTPS）、电子邮件（SMTP）、文件传输（FTP）。

**UDP（User Datagram Protocol）**：只负责发送数据包，不保证数据包能否抵达对方

- **特点**: 无连接、不可靠的数据传输。
- 功能
  - **简单高效**：不建立连接，直接发送数据，头部开销小。
  - **无序、无保障**：不保证数据到达，也不保证顺序，适合对实时性要求高而可靠性要求不高的场景。
- **应用场景**：常用于实时应用，如视频流（直播）、语音通话（VoIP）、在线游戏，以及DNS查询。

UDP也可以实现可靠传输，把TCP的特性在应用层上实现就可以，不过要实现一个商用的可靠UDP传输协议

>“应用层实现”指的是这些可靠性逻辑被写进了应用程序的代码，而不是依赖操作系统提供的TCP协议栈。

当传输的数据包大小超过了MSS( Maximum Segment Size)，就要把数据包分块，这样即使中途有一个分块丢失或者损坏了，只需要重新发送这个分块，而不是重新发送整个数据包。在TCP协议中，把每个分块称为一个TCP段（TCP Segment）。

![image-20250227220742953](C:/Users/15251/AppData/Roaming/Typora/typora-user-images/image-20250227220742953.png)

当设备作为接收方时，传输层则要负责把数据包传给应用，但是一台设备上可能会有很多应用在接受或者传输数据，因此需要一个编号将应用区分开，这个编号就是端口。

>假设你的电脑（IP地址是192.168.1.1）同时在：
>
>用浏览器访问网页（服务器IP是93.184.216.34，端口80）。
>
>用聊天软件收消息（服务器IP是203.0.113.5，端口6667）。
>
>数据包到达时：
>
>一个数据包的目标是“192.168.1.1:54321”（浏览器用的临时端口），操作系统看到54321，知道是浏览器的。
>
>另一个数据包的目标是“192.168.1.1:12345”（聊天软件的端口），操作系统看到12345，知道是聊天软件的。
>
>这里，**54321**和**12345**就是端口号，它们区分了同一台设备上的不同应用。



**网络层**

传输层可能大家刚接触的时候，会认为它负责将数据从一个设备传输到另一个设备，事实上它并不负责。实际场景中的网络环节是错综复杂的，中间有各种各样的线路和分叉路口，如果一个设备的数据要传输给另一个设备，就需要在各种各样的路径和节点进行选择，而传输层的设计理念是简单、高效、专注，如果传输层还负责这一块功能就有点违背设计原则了。
也就是说，我们不希望传输层协议处理太多的事情，只需要服务好应用即可，让其作为应用间数据传输的媒介，帮助实现应用到应用的通信，而实际的传输功能就交给下一层，也就是网络层

![image-20250227221957121](D:/interview/assets/image-20250227221957121.png)

IP协议（Internet Protocol）：IP协议会将传输层的报文作为数据部分，再加上IP包组装成IP报文，如果IP报文大小超过MTU（最大传输单元）就会再次进行切片，得到一个即将发送到网络的IP报文。

![image-20250227222431587](D:/interview/assets/image-20250227222431587.png)

IP地址的网络号（Network ID）和主机号（Host ID）是IP地址的两个核心组成部分，用于在网络中定位设备。它们是在IP协议（特别是IPv4）中通过子网掩码划分出来的，分别表示“网络”和“主机”的标识。

**网络号（Network ID）**：标识一个设备所在的网络段。所有属于同一网络的设备共享相同的网络号。

**主机号（Host ID）**：标识网络内的具体设备。同一网络中，每个设备的主机号是唯一的。

**路由（Routing）**：指的是数据包从源主机通过网络传输到目标主机的路径选择过程。它由网络层（主要是IP协议）和路由器（Router）共同实现。简单来说，路由就像导航系统，决定数据包在复杂的网络中如何“走”才能到达目的地。路由器寻址工作中，就是要找到目标地址的子网，找到后进而把数据包转发给对应的网络内。

*所以，IP 协议的寻址作用是告诉我们去往下一个目的地该朝哪个方向走，路由则是根据「下一个目的地」选择路径。寻址更像在导航，路由更像在操作方向盘*



**网络接口层**

网络接口层（Network Interface Layer），也常称为**数据链路层和物理层的组合**，是TCP/IP模型中最底层的一层。它负责将上层（网络层）的IP数据包转化为可以在物理介质上传输的信号，并在接收端将信号还原为数据包。简单来说，网络接口层是网络通信的“硬件与软件交界处”，处理设备与设备之间直接的数据传输。

![image-20250227223147200](D:/interview/assets/image-20250227223147200.png)

IP 头部中的接收方IP 地址表示网络包的目的地，通过这个地址我们就可以判断要将包发到哪里，但在以太网的世界中，这个思路是行不通的。
什么是以太网呢？电脑上的以太网接口，Wi-Fi接口，以太网交换机、路由器上的千兆，万兆以太网口，还有网线，它们都是以太网的组成部分。以太网就是一种在「局域网」内，把附近的设备连接起来，使它们之间可以进行通讯的技术。
以太网在判断网络包目的地时和IP的方式不同，因此必须采用相匹配的方式才能在以太网中将包发往目的地，而 MAC 头部就是干这个用的，所以，在以太网进行通讯要用到MAC地址。
MAC头部是以太网使用的头部，它包含了接收方和发送方的MAC地址等信息，我们可以通过ARP协议获取对方的 MAC 地址。



**总结**

![image-20250227223926179](D:/interview/assets/image-20250227223926179.png)

![image-20250227223943538](D:/interview/assets/image-20250227223943538.png)

网络接口层的传输单位是帧(frame)，IP 层的传输单位是包(packet)，TCP 层的传输单位是段(segment)，HTTP的传输单位则是消息或报文(message)。但这些名词并没有什么本质的区分，可以统称为数据包。



### 3.2

#### 1.2 键入网址到网页显示<a name="1.2-1"></a>

##### **1、第一步：对URL进行解析，从而生成发送给Web服务器的请求信息**

（a）URL元素组成：

"http:" + "//" + "Web服务器" + "/" + "目录名" + "/" + .... + "文件名"

"http:" : URL开头表示访问数据的协议

“//”：后面的字符串表示服务器的名称

（b）URL示例解析

http://www.server.com/dir1/file1.html

浏览器协议:http://

域名部分：www.server.com

数据源的路径名：/dir1/file1.html

（c）Web服务器文件路径

/...:Web服务器的根目录，这个根不是linux操作系统层面的根/，是web服务器配置文件中指定的根/，它可以是操作系统类似某个实际的某个路径

file1.html：是dir1目录下的file1.html文件

> 要是/dir1/file1.html部分省略了，那应该访问哪个文件？
>
> 当没有路径名的时候，就代表访问根目录下事先设置的默认文件，也就是/index.html，或者/default.html

##### **2、第二步：生成HTTP请求信息**

浏览器确定了Web服务器和文件名，接下来就是来根据这些信息来生产HTTP请求

在对 URL 进行解析并确定要发送给 Web 服务器的请求信息后，生成 HTTP 请求信息的过程是一个系统化的步骤。

**（a）URL 解析**

首先，浏览器或客户端需要解析输入的 URL，提取关键信息。这些信息将用于构建 HTTP 请求。假设 URL 是 `https://www.example.com/blog/article1?param1=value1#section1`：

- **协议**: `https://`（表示使用加密的 HTTP，通常通过端口 443）。
- **域名**: `www.example.com`（通过 DNS 解析为 IP 地址，如 `93.184.216.34`）。
- **路径**: `/blog/article1`（请求的资源位置）。
- **查询参数**: `?param1=value1`（可选，用于传递额外数据）。
- **片段（Fragment）**: `#section1`（仅用于客户端导航，不发送给服务器）。

解析后，浏览器确定：

- 需要连接到 `www.example.com` 的服务器。
- 请求路径是 `/blog/article1`，可能带查询参数 `param1=value1`。
- 使用 HTTPS 协议，因此需要 TLS 加密。

**（b） 确定请求方法**

根据用户操作，浏览器选择合适的 HTTP 方法：

- 如果只是打开网页，通常使用 `GET` 方法（获取资源）。
- 如果是提交表单，可能使用 `POST` 方法（发送数据）。

对于 `https://www.example.com/blog/article1?param1=value1`，默认使用 `GET` 方法，因为这是一个简单的资源获取请求。

**（c）构建 HTTP 请求的各个部分**

生成 HTTP 请求信息包括以下几个主要部分：

(1) 请求行（Request Line）

请求行是 HTTP 请求的第一行，格式为：

```
<方法> <路径+查询参数> <HTTP版本>
```

- **方法**: `GET`（对于这个例子）。
- **路径+查询参数**: `/blog/article1?param1=value1`（路径是 `/blog/article1`，查询参数附加在后面）。
- **HTTP 版本**: `HTTP/1.1`（现代浏览器通常支持 HTTP/1.1 或 HTTP/2，但默认格式还是 HTTP/1.1）。

因此，请求行可能是：

```
GET /blog/article1?param1=value1 HTTP/1.1
```

(2) 请求头（Request Headers）

请求头提供附加信息，帮助服务器理解和处理请求。浏览器会自动生成常见的头字段，例如：

- **Host**: 指定目标域名，必须字段。

  ```
  Host: www.example.com
  ```

- **User-Agent**: 标识客户端的浏览器或设备。

  ```
  User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36
  ```

- **Accept**: 客户端接受的内容类型。

  ```
  Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
  ```

- **Accept-Language**: 语言偏好。

  ```
  Accept-Language: zh-CN,zh;q=0.9,en;q=0.8
  ```

- **Connection**: 连接管理（通常为 `keep-alive`）。

  ```
  Connection: keep-alive
  ```

其他可能头字段包括：

- `Referer`: 上一个访问的页面 URL（如果有）。
- `Cookie`: 客户端的会话信息（如果之前有登录或设置）。

所有头字段以 `字段名: 字段值` 格式书写，每行以 `\r\n` 结尾。头字段结束后，添加一个空行（`\r\n`），表示头部分结束。

(3) 请求主体（Request Body）（可选）

对于 `GET` 请求，通常没有请求体，因为数据通过查询参数（如 `?param1=value1`）传递。如果是 `POST` 请求，则可能包含主体数据，例如表单数据或 JSON。

对于这个例子（`GET` 请求），请求体为空。

**（d） 组装完整的 HTTP 请求**

将上述部分组合，形成完整的 HTTP 请求。例如：

```
GET /blog/article1?param1=value1 HTTP/1.1
Host: www.example.com
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
Accept-Language: zh-CN,zh;q=0.9,en;q=0.8
Connection: keep-alive

```

- 每行以 `\r\n` 分隔。
- 头字段后有一个空行（`\r\n`），表示请求结束（如果没有主体）。

**（e）HTTPS 的特殊处理**

因为 URL 使用 `https://`，浏览器需要在发送 HTTP 请求之前执行以下步骤：

- TLS 握手:
  - 浏览器与服务器协商加密算法和密钥。
  - 验证服务器证书（确保是 `www.example.com` 的合法证书）。
- 加密请求:
  - 将生成的 HTTP 请求通过 TLS 层加密后发送到服务器（端口 443）。

**（f）发送请求**

- 浏览器通过已建立的 TCP 连接将加密后的 HTTP 请求发送到服务器的 IP 地址（`93.184.216.34`）。
- 服务器接收请求后，解析并返回响应（如 HTML 内容）。

##### **3、第三步：真实地址查询——DNS**

通过浏览器解析URL并且生成HTTP消息之后，需要操作系统把消息发送给Web服务器，但是在发送之前，还需要查询服务器域名对应的IP地址。因为发送消息时，必须提供对象的IP地址。

> 在发送消息之前，必须将域名 www.example.com 转换为对应的 IP 地址。这个过程称为**域名解析**（Domain Name Resolution）。

所以有一种服务器专门保存了Web服务器域名和IP的对应关系，它就是DNS服务器

**域名的层级关系**

DNS中的域名都是用句点来分隔的，比如www.server.com，这里的句点代表了不同层次之间的界限。越靠右的位置代表其层级越高。

实际上域名还有最后一个点，比如www.server.com.，这个最后一个点代表根域名。

所以该域名的层级关系类似一个树状结构：

- 根DNS服务器（.）
- 顶级域DNS服务器（.com）
- 权威DNS服务器（server.com）

![image-20250302131531709](D:/interview/assets/image-20250302131531709.png)

客户端只要能够找到任意一台DNS服务器，就可以通过它找到根域DNS服务器，然后再一路顺藤摸瓜找到位于下层的某台目标DNS服务器。

**域名解析的流程**

**(a) 本地缓存检查**

- **步骤**:
  - 首先，客户端（通常是用户的设备，如电脑或手机）会检查本地的 DNS 缓存。
  - 本地缓存可能存储在操作系统的 DNS 解析库（如 Windows 的 `nscd` 或 macOS 的 `mDNSResponder`）或浏览器的缓存中。
  - 如果之前访问过 `www.example.com`，其对应的 IP 地址可能已经缓存（通常有生存时间 TTL，Time to Live，限制缓存有效期）。
- **如果命中缓存**:
  - 直接返回缓存中的 IP 地址（例如 `93.184.216.34`），解析结束。
  - 节省时间（通常几毫秒），避免网络查询。
- **如果未命中**:
  - 继续向外部 DNS 服务器发起查询。

**(b) 查询本地 DNS 服务器**

- **步骤**:
  - 操作系统通过网络协议（通常是 UDP 协议，端口 53）联系配置的本地域名服务器（Local DNS Server）。
  - 本地 DNS 服务器通常由你的互联网服务提供商（ISP）提供，也可能是企业或公共 DNS（如 Google 的 `8.8.8.8` 或 Cloudflare 的 `1.1.1.1`）。
- **本地 DNS 服务器的处理**:
  - 本地 DNS 服务器检查自己的缓存。如果缓存中有 `www.example.com` 的记录，直接返回 IP 地址。
  - 如果缓存中没有，进入递归查询或迭代查询过程。

**(c) 递归查询或迭代查询**

DNS 服务器通过层次化的查询系统解析域名，通常涉及以下层次的 DNS 服务器：

- **根域名服务器（Root Name Servers）**:
  - 全球共有 13 组根域名服务器（用字母 A 到 M 表示，如 `a.root-servers.net`）。
  - 本地 DNS 服务器发送查询给根域名服务器，询问 `www.example.com` 的信息。
  - 根服务器不存储具体域名的 IP，但知道顶级域名（TLD，如 `.com`）的权威服务器地址。
  - 根服务器返回 `.com` 的权威 DNS 服务器地址。

- **顶级域名服务器（TLD Name Servers）**:
  - 本地 DNS 服务器接着联系 `.com` 的权威服务器（例如 Verisign 管理 `.com` 的 TLD 服务器）。
  - TLD 服务器知道 `example.com` 的权威 DNS 服务器地址。
  - 返回 `example.com` 的权威服务器地址。

- **权威域名服务器（Authoritative Name Servers）**:
  - 本地 DNS 服务器联系 `example.com` 的权威服务器（由域名注册商或网站所有者配置）。
  - 权威服务器存储 `www.example.com` 的具体 IP 地址（例如 `93.184.216.34`）。
  - 返回 `www.example.com` 的 IP 地址。

- **查询类型**:
  - **递归查询**: 本地 DNS 服务器负责完成整个查询过程（从根到权威服务器），并返回最终结果给客户端。
  - **迭代查询**: 本地 DNS 服务器只向根服务器查询，然后根服务器返回 TLD 服务器地址，TLD 服务器返回权威服务器地址，依次迭代，直到获取 IP 地址。现代 DNS 通常使用递归查询以简化客户端操作。

**(d) 返回 IP 地址**

- 本地 DNS 服务器收到 `www.example.com` 的 IP 地址（如 `93.184.216.34`）后：
  - 将结果返回给客户端（浏览器或操作系统）。
  - 同时，本地 DNS 服务器会缓存这个结果（根据 TTL 决定缓存时间，通常几小时到几天）。

**(e) 客户端使用 IP 地址**

- 客户端（操作系统或浏览器）接收到 IP 地址后，结合之前解析的 URL（路径、参数等）：
  - 建立与目标服务器的 TCP 连接（端口通常为 80 或 443）。
  - 发送之前生成的 HTTP 请求（如 `GET /blog/article1 HTTP/1.1`）。

>示例：解析 `www.example.com`

>假设你在浏览器输入 `www.example.com`，解析流程可能如下：
>
>1. 本地缓存无记录，操作系统联系本地 DNS 服务器（例如 `8.8.8.8`）。
>
>2. 本地 DNS 服务器查询根服务器（`a.root-servers.net`），获知 `.com` 的 TLD 服务器地址。
>
>3. 联系 `.com` 的 TLD 服务器，获知 `example.com` 的权威服务器地址。
>
>4. 联系 `example.com` 的权威服务器，获取 `www.example.com` 的 IP 地址（例如 `93.184.216.34`）。
>
>5. 本地 DNS 服务器返回 IP 地址给操作系统，浏览器使用该 IP 建立连接并发送 HTTP 请求。
>
>  整个过程通常在几毫秒到几百毫秒内完成，具体取决于网络延迟和缓存情况。

![image-20250302132752251](D:/interview/assets/image-20250302132752251.png)

##### **4、第四步：TCP的可靠传输**

**TCP包头格式（TCP Header）**

![image-20250302134038947](D:/interview/assets/image-20250302134038947.png)

端口号和目标端口号（Source port, Destination port）：源端口号是发送方（客户端或服务器）使用的端口号，用于标识发起通信的应用程序或进程。目的端口号是接收方（服务器或客户端）使用的端口号，用于标识目标应用程序或服务。

序号：序列号表示发送的 TCP 数据段中第一个字节的序列号，用于标识数据的顺序。

确认序列：确认号表示接收方期望接收的下一个数据段的第一个字节的序列号。

状态位： 状态位（也叫标志位）是 TCP 包头中的 6 个控制位，用于管理连接状态和行为。包括：

- URG（Urgent Pointer 有效）: 紧急指针有效（通常未使用）。
- ACK（Acknowledgment 有效）: 确认号有效（大多数数据包设置此位）。
- PSH（Push 函数）: 提示接收方立即将数据传递给应用程序（减少缓冲）。
- RST（Reset）: 重置连接（用于异常情况）。
- SYN（Synchronize）: 建立连接（用于三次握手的第一个和第二个包）。
- FIN（Finish）: 关闭连接（用于四次挥手）。

窗口大小：窗口大小表示发送方当前允许接收方的最大接收窗口大小（以字节为单位）。

校验和： 校验和是 TCP 包头的错误检测值，覆盖包头、数据和伪首部（包含源 IP、目标 IP、协议类型等）。

紧急指针：紧急指针在 URG 标志置位时有效，指示紧急数据的结束位置。

选项： 选项字段是可变的，用于扩展 TCP 功能，长度必须是 4 字节的整数倍（通过填充补齐）。

数据：数据是 TCP 包头的后续部分，包含实际传输的应用层数据（如 HTTP 请求或响应）。

**TCP传输数据之前，要先三次握手建立连接**

三次握手（Three-Way Handshake）是 TCP（传输控制协议）在传输数据之前，用于建立可靠连接的初始化过程。通过三次交互，发送方和接收方协商初始序列号（ISN）、确认连接状态，并确保双方都能正常通信。这是 TCP 提供可靠、面向连接传输的基础。

以下是 TCP 三次握手的详细过程（以客户端访问服务器为例，如浏览器访问 www.example.com）：

(a) **第一次握手（SYN）**

- 步骤:
  - 客户端（发送方）向服务器（接收方）发送一个 TCP 数据段，设置以下内容：
    - **标志位**: SYN（Synchronize）= 1，表示请求建立连接。
    - **序列号（Sequence Number，ISN）**: 客户端随机生成一个初始序列号（例如 1000），用于后续数据的标识。
    - 其他字段（如源端口、目的端口）也已设置（例如源端口 49152，目的端口 443）。
  - 数据段不包含实际数据。
- 作用:
  - 客户端通知服务器：“我希望建立连接，我的初始序列号是 1000，你能接收吗？”
- 服务器响应:
  - 服务器接收到 SYN 包后，如果愿意建立连接（端口可用），进入“同步接收（SYN-RECEIVED）”状态。

(b) **第二次握手（SYN+ACK）**

- 步骤:
  - 服务器回应客户端一个 TCP 数据段，设置以下内容：
    - **标志位**: SYN=1（表示同意建立连接），ACK=1（确认客户端的 SYN）。
    - **序列号（Sequence Number）**: 服务器生成自己的初始序列号（例如 2000）。
    - **确认号（Acknowledgment Number）**: 服务器将确认号设为客户端的序列号+1（例如 1001），确认已接收客户端的 SYN。
  - 数据段不包含实际数据。
- 作用:
  - 服务器通知客户端：“我收到你的请求，同意建立连接，我的初始序列号是 2000，你能接收吗？我确认你的序列号是 1000。”
- 客户端响应:
  - 客户端接收到 SYN+ACK 包后，进入“已建立（ESTABLISHED）”状态。

(c) **第三次握手（ACK）**

- 步骤:
  - 客户端回应服务器一个 TCP 数据段，设置以下内容：
    - **标志位**: ACK=1（确认服务器的 SYN）。
    - **序列号（Sequence Number）**: 客户端的序列号为之前 SYN 的确认号（1001）。
    - **确认号（Acknowledgment Number）**: 客户端将确认号设为服务器的序列号+1（例如 2001），确认已接收服务器的 SYN。
  - 数据段不包含实际数据。
- 作用:
  - 客户端通知服务器：“我收到你的响应，连接已建立，可以开始传输数据。”
- 服务器响应:
  - 服务器接收到 ACK 包后，也进入“已建立（ESTABLISHED）”状态。连接正式建立，双方可以开始数据传输。

![image-20250302135442964](D:/interview/assets/image-20250302135442964.png)

**TCP报文生成**

TCP协议里面有两个端口，一个是浏览器监听的端口，一个是Web服务器监听的端口。

在双方建立了连接后，TCP报文中的数据部分就是存放再HTTP头部+数据，组装成TCP报文之后，就需要交给下面的网络层处理

![image-20250302140808339](D:/interview/assets/image-20250302140808339.png)

##### **5、第五步：远程定位——IP**

TCP模块再执行连接、收发、断开等各种阶段操作时，都需要委托IP模块将数据封装成网络包发送给通信对象。

**IP包头格式**

IP报文头部的格式：
![image-20250302141117882](D:/interview/assets/image-20250302141117882.png)

在IP协议里面需要有源地址IP和目标地址IP

- 源地址，就是客户端输出的IP地址
- 目标地址，就是通过DNS域名解析得到的Web服务器IP

> 假设客户端有多个网卡，就会有多个IP地址，那头部的源地址应该选择哪个IP呢？
>
> 相当于在多块网卡中判断应该使用哪个一块网卡来发送包，这个时候就要根据路由表规则，来判断哪一个网卡作为源地址IP

**IP报文生成**

网络包的报文如下图：

![image-20250302145638952](D:/interview/assets/image-20250302145638952.png)

##### **6、第六步：两点传输——MAC**

生成了IP头部之后，接下来网络包还需要在IP头部的前面加上MAC头部

**MAC包头格式**

![image-20250302145835285](D:/interview/assets/image-20250302145835285.png)

在MAC包头里需要发送方MAC地址和接收方目标MAC地址，用于两点之间的传输

一般在TCP/IP通信里，MAC包头的协议类型只使用：

- 0800：IP协议
- 0806：ARP协议

以下是 MAC 层在整个过程中扮演的角色，从键入 URL 到数据在本地网络传输的步骤：

**(a) 准备阶段：生成 Ethernet 帧**

- **输入**: 从网络层接收 IP 数据包（包含 IP 包头 + TCP 报文 + HTTP 数据）。
- 操作:
  - MAC 层为 IP 数据包添加 MAC 包头和尾部，形成 Ethernet 帧。
  - MAC 包头的组成（以 Ethernet II 帧为例）：
    - **目标 MAC 地址（6 字节）**: 标识本地网络中的目标设备（如路由器的 MAC 地址，或目标服务器的 MAC 地址）。
    - **源 MAC 地址（6 字节）**: 标识发送设备的 MAC 地址（如客户端网卡的 MAC 地址）。
    - **类型/以太网类型（2 字节）**: 指定上层协议（如 0x0800 表示 IPv4）。
  - **帧尾（FCS，4 字节）**: 添加帧校验序列（通过 CRC-32 计算），用于错误检测。
- 示例:
  - 假设客户端 IP 为 192.168.1.1，MAC 地址为 00:1A:2B:3C:4D:5E；路由器 IP 为 192.168.1.1，MAC 地址为 00:50:56:C0:00:01。
  - MAC 层生成 Ethernet 帧，目标 MAC 地址为 00:50:56:C0:00:01，源 MAC 地址为 00:1A:2B:3C:4D:5E，类型为 0x0800。

**(b) 地址解析（ARP 协议）**

- 操作:
  - 如果发送方不知道目标设备的 MAC 地址（例如目标是路由器或服务器），MAC 层通过 ARP（地址解析协议）查询。
  - 发送方广播 ARP 请求（如 “谁拥有 IP 地址 192.168.1.1？”），目标设备（路由器）回复其 MAC 地址（如 00:50:56:C0:00:01）。
  - ARP 缓存本地存储结果，加速后续通信。
- 作用:
  - 确保数据帧的目标 MAC 地址正确，避免发送到错误设备。
- 示例:
  - 客户端通过 ARP 发现路由器的 MAC 地址 00:50:56:C0:00:01，用于填充目标 MAC 地址。

**(c) 冲突检测与介质访问（CSMA/CD）**

- 操作

  (适用于半双工 Ethernet)：

  - 在共享介质（如老式集线器）中，MAC 层使用 CSMA/CD（载波侦听多路访问/冲突检测）协议：
    - 侦听网络介质（电缆），如果空闲，发送数据帧。
    - 如果检测到冲突（多个设备同时发送），停止发送，等待随机时间后重试。
  - 在现代全双工 Ethernet（使用交换机）中，无需 CSMA/CD，交换机直接管理流量。

- 作用:

  - 防止数据帧在共享介质中冲突，确保成功传输。

- 示例:

  - 客户端检查网络空闲后，发送 Ethernet 帧；如果另一设备同时发送，双方暂停，等待后重试。

**(d) 发送 Ethernet 帧**

- 操作:
  - MAC 层通过网络接口控制器（NIC）将 Ethernet 帧发送到物理层。
  - 物理层将帧转换为电信号（通过电缆）或无线信号（通过 Wi-Fi），传输到下一跳设备（如路由器）。
- 作用:
  - 完成从数据链路层到物理层的转换，使数据进入网络。
- 示例:
  - Ethernet 帧通过 RJ45 电缆或 Wi-Fi 信号发送到路由器。

**(e) 接收方的处理**

- 操作 (在接收设备，如路由器或目标服务器)：
  - 接收方（NIC）检查目标 MAC 地址：
    - 如果匹配本设备的 MAC 地址（或广播地址），接受数据帧。
    - 如果不匹配，丢弃数据帧。
  - 验证 FCS（重新计算 CRC-32，与发送方对比）：
    - 如果一致，确认数据完整，传递给网络层（IP 层）。
    - 如果不一致，丢弃数据帧。
- 作用:
  - 确保数据帧送达正确设备，并验证完整性。
- 示例:
  - 路由器接收到目标 MAC 地址为 00:50:56:C0:00:01 的帧，匹配本机地址，验证 FCS 后将 IP 数据包交给 IP 层。

至此，网络包的报文如下图：

![image-20250302150744738](D:/interview/assets/image-20250302150744738.png)

##### **7、第七步：出口——网卡（Network Interface Card，NIC）**

网络包只是一串二进制数字信息，没办法真正发送给对方，因此，需要把数字信号转换为电信号，才能在网线上传输。

负责执行的这一操作的是网卡，要控制网卡还需要靠网卡驱动程序。

网卡驱动获取网络包之后，会将其复制到网卡内的缓存区中，接着会在其开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列。

![image-20250302151430641](D:/interview/assets/image-20250302151430641.png)

最后网卡会将包转换位电信号，通过网线发送出去。

##### **8、第八步：送别者——交换机**

交换机的设计是将网络包原样转发到目的地，交换机工作在MAC层，也称为二层网络设备。

电信号到达网线接口，交换机里的模块进行接受，接下来交换机里的模块将电信号转换为数字信号。然后通过包末尾的FCS校验错误，如果没问题则放到缓冲去。这部分操作基本和计算机网卡相同，但交换机的工作方式和网卡不同。

计算机的网卡本身具有MAC地址，并通过核对收到的包的接收方MAC地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方MAC地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，交换机的端口不具有MAC地址。

交换机根据MAC地址表查找MAC地址，然后将信号发送到相应的端口

> 当MAC地址表找不到指定的MAC地址会怎么样？
>
> 地址表中找不到指定的MAC地址。这可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备一段时间没有工作导致地址被从地址表中删除了。
> 这种情况下，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。
> 这样做不会产生什么问题，因为以太网的设计本来就是将包发送到整个网络的，然后只有相应的接收者才接收包，而其他设备则会忽略这个包。

##### **9、第九步：出境大门——路由器**

路由器是一种网络设备，连接多个网络（如家庭局域网和互联网），通过 IP 地址和路由表转发数据包。

> 路由器与交换机的区别？
>
> 网络包经过交换机之后，现在到达了路由器，并在此被转发到下一个路由器或目标设备。这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。
> 不过在具体的操作过程上，路由器和交换机是有区别的。
>
> ·因为路由器是基于IP设计的，俗称三层网络设备，路由器的各个端口都具有MAC地址和IP地址；
> 而交换机是基于以太网设计的，俗称二层网络设备，交换机的端口不具有MAC地址。

**路由器基本原理**

路由器的端口有MAC地址，因此可以成为以太网的发送方和接收方；同时还具有IP地址。当转发包的时候，首先路由器端口会接受发给自己的以太网包，然后路由器表查询转发目标，在由相应的端口作为发送方将以太网发送出去。

**路由器的包接收操作**

首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包未尾的FCS进行错误校验。如果没问题则检查MAC头部中的接收方MAC地址，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。
总的来说，路由器的端口都具有MAC地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。

**查询路由表确定输出端口**

完成包接收操作之后，路由器就会去掉包开头的MAC头部。

MAC头部的作用就是将包送达路由器，其中的接收方MAC地址就是路由器端口的MAC地址。因此，当包到达路由器之后，MAC头部的任务就完成了，于是MAC头部就会被丢弃。
接下来，路由器会根据MAC头部后方的IP头部中的内容进行包的转发操作。
转发操作分为几个阶段，首先是查询路由表判断转发目标。

**路由器的发送操作**

接下来就会进入包的发送操作。

首先，我们需要根据路由表的网关列判断对方的地址。

- 如果网关是一个IP地址，则这个IP地址就是我们要转发到的目标地址，还未抵达终点，还需继续需要路由器转发。
- 如果网关为空，则IP头部中的接收方IP地址就是要转发到的目标地址，也是就终于找到IP包头里的目标地址了，说明已抵达终点。

知道对方的IP地址之后，接下来需要通过ARP协议根据IP地址查询MAC地址，并将查询的结果作为接收方MAC地址。
路由器也有ARP缓存，因此首先会在ARP缓存中查询，如果找不到则发送ARP查询请求。
接下来是发送方MAC地址字段，这里填写输出端口的MAC地址。还有一个以太类型字段，填写0800（十六进制）表示IP协议。
网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。
发送出去的网络包会通过交换机到达下一个路由器。由于接收方MAC地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。

接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地。

**在网络包传输的过程中，源IP和目标IP始终是不会变的，一直变化的是MAC地址,因为需要MAC地址在以太网内进行两个设备之间的包传输。**

##### **10、第十步：互相扒皮——服务器和客户端**

![image-20250302154337726](D:/interview/assets/image-20250302154337726.png)

服务器（www.example.com）接收到客户端发送的 Ethernet 帧后，通过协议栈逐层剥离头部，提取 HTTP 数据并处理。以下是详细步骤：

(a) 物理层：信号接收

- 操作:
  - 服务器的网卡通过物理接口（RJ45 或 Wi-Fi）接收电信号或无线信号。
  - 解码信号，恢复为二进制数据（Ethernet 帧）。
- 输出:
  - Ethernet 帧（MAC 包头 + IP 数据包 + FCS）。
- 示例:
  - 从电缆接收电信号，解码为二进制数据。

(b) 数据链路层：MAC 剥离

- 操作:
  - 网卡检查目标 MAC 地址是否匹配服务器的 MAC 地址（如 00:50:56:C0:00:03）。
  - 验证 FCS（重新计算 CRC-32，与发送方对比），确认数据未损坏。
  - 剥离 MAC 包头（14 字节）和 FCS（4 字节），提取 IP 数据包。
  - 如果不匹配或 FCS 错误，丢弃帧。
- 输出:
  - IP 数据包（IP 包头 + TCP 报文 + HTTP 数据）。
- 示例:
  - 剥离后提取 IP 数据包，目标 IP 为 93.184.216.34。

(c) 网络层：IP 剥离

- 操作:
  - IP 层检查 IP 包头的首部校验和，确认完整性。
  - 检查目标 IP 地址（93.184.216.34）是否匹配本机 IP。
  - 剥离 IP 包头（20 字节），提取 TCP 报文。
  - 更新 TTL（减 1），处理分片（如果有）。
  - 如果 TTL 为 0 或目标不匹配，丢弃数据包并可能发送 ICMP 错误。
- 输出:
  - TCP 报文（TCP 包头 + HTTP 数据）。
- 示例:
  - 剥离后提取 TCP 报文，目的端口为 443。

(d) 传输层：TCP 剥离

- 操作:
  - TCP 层检查 TCP 包头的序列号、确认号和标志位，确认数据完整性和顺序。
  - 剥离 TCP 包头（20 字节），提取 HTTP 数据。
  - 如果需要（例如数据丢失），通过重传机制（基于序列号和确认号）请求重发。
- 输出:
  - HTTP 数据（GET / HTTP/1.1...）。
- 示例:
  - 提取 HTTP 请求，交给应用层处理。

(e) 应用层：HTTP 处理

- 操作:
  - 服务器的 Web 应用（如 Nginx 或 Apache）解析 HTTP 请求（如 GET / HTTP/1.1）。
  - 根据路径（/）查找资源（如 HTML 文件），生成 HTTP 响应（如 200 OK 和 HTML 内容）。
- 输出:
  - HTTP 响应数据（HTTP/1.1 200 OK\r\nContent-Type: text/html\r\n...\r\n<html>...）。
- 示例:
  - 服务器返回 HTML 页面，供客户端渲染。



### 3.3

#### 1.3 Linux系统是如何收发网络包<a name="1.3-1"></a>

##### 1、网络模型

为了解决各种设备在网络互联中的兼容性的问题，制定了OSI网络模型

该模型主要有7层，分别是

- 应用层：负责给应用程序提供接口
- 表示层：负责把数据转换成兼容另一个系统能识别的格式
- 会话层：负责建立、管理和终止表示层实体之间的通信会话
- 传输层：负责端到端的数据传输
- 网络层：负责数据的路由、转发、分片
- 数据链路层：负责数据的封帧和差错检测，以及MAC寻址
- 物理层：负责在物理网络中数据传输帧

TCP/IP与OSI网络模型的区别：

![image-20250303144038483](D:/interview/assets/image-20250303144038483.png)

##### 2、Linux网络协议栈

![image-20250303144248292](D:/interview/assets/image-20250303144248292.png)

- 应用程序需要通过系统调用，来跟Socket层进行数据交互
- Socket层的下面就是传输层、网络层和网络接口层
- 最下面的一层，就是网卡驱动程序和硬件网卡设备

##### 3、Linux接收网络包的流程

![image-20250303150216591](D:/interview/assets/image-20250303150216591.png)

首先，会进入到网络接口层，在这一层会检查报文的合法性，如果不合法则丢弃，合法则会找出该网络包的上层协议的类型，比如是IPv4，还是IPv6，接着再去掉帧头和帧尾，然后再交给网络层。

到了网络层，取出IP包，判断网络包下一步的走向。当确认要发送给本机之后，就会从IP头里看看上一层协议的类型是TCP还是UDP，接着去掉IP头，然后交给传输层。

传输层取出TCP头或者UDP头，根据四元组“源IP、源端口、目的IP、目的端口”作为标识，找出对应的Socket，并把数据放入Socket的接收缓冲区。

最后，应用层调用Socket接口，将内核的Socket接收缓冲区的数据拷贝到应用层的缓冲区，然后唤醒用户进程。

> 如何告诉操作系统这个网络包以及到达了呢？
>
> 最简单的一种方式就是触发中断，每当网卡收到一个网络包，就出发一个中断告诉操作系统。但是，再高性能场景下，网络包的数量会非常多，会触发很多中断。CPU收到中断会停下手里的事情来处理中断，这回导致整体效率的下滑。
>
> 因此，引入一种机制，NAPI机制。它的核心概念就是不采用中断的方式读取数据，而是首先采用中断唤醒数据接收的服务程序，然后poll的方法来轮询数据。
>
> 当有网络包到达时，会通过DMA技术，将网络包写入到指定的内存地址，接着网卡向CPU发起硬件中断，当CPU收到硬件中断请求后，根据中断表，调用以及注册的中断处理函数。



##### 3、Linux发送网络包的流程

首先，应用程序会调用Socket发送数据包的接口，由于这个是系统调用，所以会从用户态陷入到内核态中的Socket层，内核会申请一个内核态的sk_buff（socket buffer）内存，将用户待发送的数据拷贝到sk_buff内存，并将其加入到发送缓冲区。

接下来，网络协议栈会从Socket发送缓冲区中取出sk_buff，并按照TCP/IP协议栈从上到下逐层处理。

如果使用的是TCP传输协议发送数据，那么先拷贝一个新的sk_buff副本，这是因为sk_buff后续在调用网络层，最后到达网卡发送完成的时候，这个sk_buf会被释放掉。而TCP协议是支持丢失重传的，在收到对方的ACK之前，这个sk_buff不能被删除。所以内核的做法就是每次调用网卡发送的时候，传递的是sk_buff的拷贝，等收到ACK再真正删除。

接着，对sk_buff填充TCP头。

> 在层级之间传递数据的时候，不发生拷贝，只用sk_buff来描述所有的网络包，比如做到的?
> 当接收报文时，从网卡驱动开始，通过协议栈层层往上传送数据包，通过增加skb->data的值，来逐步剥离协议首部。
>
> 当要发送报文时，创建sk_buff结构体，数据缓存区的头部预留足够的空间，用来填充各层首部，在经过各下层协议时，通过减少skb->data的值来增加协议首部。

![image-20250303163350657](D:/interview/assets/image-20250303163350657.png)

然后交给网络层，在网络层里会做这些工作：选取路由（确定下一跳的IP）、填充IP头部、netfilter过滤、对超过MTU大小的数据包进行分片。处理完这些工作后会交给网络接口层处理。

网络接口层会通过ARP协议获得下一条的MAC地址，然后对sk_buff填充帧头和帧尾，接着将sk_buff放到网卡的发送队列中。

这一些工作准备好之后，会触发软中断告诉网卡驱动程序，驱动程序会从发送队列中读取sk_buff，将这个sk_buff挂到RingBuffer中，接着将sk_buff数据映射到网卡可访问的内存DMA区域，最后触发真实的发送。

数据发送完成后，网卡设备会出发一个硬中断来释放内存，主要释放sk_buff内存和清理RingBuffer内存。

最后，当收到TCP报文的ACK应答时，传输层就会释放原始的sk_buff

>发送⽹络数据的时候，涉及几次内存拷⻉操作？
>
>第⼀次，调⽤发送数据的系统调⽤的时候，内核会申请⼀个内核态的 sk_buff 内存，将⽤户待发送的数据拷⻉到 sk_buff 内存，并将其加⼊到发送缓冲区。 
>
>第⼆次，在使⽤ TCP 传输协议的情况下，从传输层进⼊⽹络层的时候，每⼀个 sk_buff 都会被克隆⼀个新的副本出来。副本 sk_buff 会被送往⽹络层，等它发送完的时候就会释放掉，然后原始的  sk_buff 还保留在传输层，⽬的是为了实现 TCP 的可靠传输，等收到这个数据包的 ACK 时，才会释放原始的 sk_buff 。 
>
>第三次，当 IP 层发现 sk_buff ⼤于 MTU 时才需要进⾏。会再申请额外的 sk_buff，并将原来的 sk_buff 拷 ⻉为多个⼩的 sk_buff。 





### 3.4

#### 2.1 HTTP面试题<a name="2.1"></a>

##### 1、HTTP基本概念

**（1）HTTP是什么？**

HTTP 是超文本传输协议，也就是**H**yper Text **T**ransfer **P**rotocol。

![image-20250304101506874](D:/interview/assets/image-20250304101506874.png)

- 协议：HTTP 是一个用在计算机世界里的**协议**。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范（**两个以上的参与者**），以及相关的各种控制和错误处理方式（**行为约定和规范**）。

- 传输：HTTP 是一个在计算机世界里专门用来在**两点之间传输数据**的约定和规范。

> 比如在访问百度网站的时候，浏览器把请求数据发送给百度网站，网站再把一些数据返回给浏览器，最后由浏览器渲染在屏幕，就可以看到图片和视频了。

- 超文本：HTTP传输的内容是超文本，它就是**超越了普通文本的文本**，它是文字、图片、视频等的混合体，最关键有超链接，能从一个超文本跳转到另外一个超文本。

**（2）HTTP 常见的状态码有哪些？**

![image-20250304102156494](D:/interview/assets/image-20250304102156494.png)

1xx - 信息类（临时响应）

- **100 Continue**：客户端应继续发送请求的剩余部分。
- **101 Switching Protocols**：服务器根据客户端请求切换协议（如从HTTP切换到WebSocket）。

2xx - 成功类

- **200 OK**：请求成功，服务器返回了所需的数据。
- **201 Created**：请求已成功，并创建了新资源（如POST请求后）。
- **204 No Content**：请求成功，但响应中没有内容返回（常用于删除操作）。

3xx - 重定向类

- **301 Moved Permanently**：资源已永久移动到新URL，客户端应更新链接。
- **302 Found**：资源临时移动到新URL，客户端应继续使用原URL。
- **304 Not Modified**：资源未更改，客户端可以使用缓存版本。

4xx - 客户端错误类

- **400 Bad Request**：请求语法错误或参数无效，服务器无法处理。
- **401 Unauthorized**：请求需要身份验证，客户端未提供有效凭据。
- **403 Forbidden**：服务器理解请求，但拒绝执行（权限不足）。
- **404 Not Found**：服务器找不到请求的资源。
- **429 Too Many Requests**：客户端在限定时间内发送了过多请求（通常与API限流相关）。

5xx - 服务器错误类

- **500 Internal Server Error**：服务器内部错误，无法完成请求。
- **502 Bad Gateway**：作为网关或代理的服务器从上游服务器收到无效响应。
- **503 Service Unavailable**：服务器暂时无法处理请求（可能是维护或过载）。
- **504 Gateway Timeout**：网关或代理服务器未及时从上游服务器收到响应。

**（3）HTTP 常见字段有哪些？**

- **Host**：指定请求的目标域名和端口（HTTP/1.1必填），如 Host: www.example.com。

![image-20250304102904447](D:/interview/assets/image-20250304102904447.png)

- **Content-Length**：消息体的字节长度，如 Content-Length: 1024。

![image-20250304102928517](D:/interview/assets/image-20250304102928517.png)

- **Connection**：控制连接选项，如 Connection: keep-alive（保持连接）或 Connection: close。开启了 HTTP Keep-Alive 机制后， 连接就不会中断，而是保持连接。当客户端发送另一个请求时，它会使用同一个连接，一直持续到客户端或服务器端提出断开连接。

![image-20250304102959462](D:/interview/assets/image-20250304102959462.png)

- **Content-Type**：指定消息体的媒体类型，如 Content-Type: application/json 或 Content-Type: text/html; charset=UTF-8。

![image-20250304103055534](D:/interview/assets/image-20250304103055534.png)

- **Content-Encoding**：消息体的编码方式，如 Content-Encoding: gzip。

![image-20250304103133164](D:/interview/assets/image-20250304103133164.png)



##### 2、GET与POST

**（1）GET 和 POST 有什么区别？**

**GET**：用于从服务器**获取数据**，通常是查询或读取资源（如获取网页内容、API数据）。**GET 的语义是从服务器获取指定的资源**，这个资源可以是静态的文本、页面、图片视频等。GET 请求的参数位置一般是写在 URL 中，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制（HTTP协议本身对 URL长度并没有做任何规定）。

**POST**：用于向服务器**提交数据**，通常涉及创建或更新资源（如提交表单、上传文件）。**POST 的语义是根据请求负荷（报文body）对指定的资源做出处理**，具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中，body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。

**（2）GET 和 POST 方法都是安全和幂等的吗？**

安全：在 HTTP 上下文中，“安全”指的是方法是否会改变服务器上的资源状态（即是否有副作用）。安全的 HTTP 方法仅用于读取数据，不会修改服务器状态。

幂等：幂等性指的是同一请求执行一次与多次的结果是否相同，即多次请求不会产生额外的副作用。

- **GET 方法就是安全且幂等的**，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以，**可以对 GET 请求的数据做缓存，这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），而且在浏览器中 GET 请求可以保存为书签**。
- **POST** 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是**不安全**的，且多次提交数据就会创建多个资源，所以**不是幂等**的。所以，**浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签**。

> GET请求可以带body吗？
>
> 理论上，任何请求都可以带body。大多数 HTTP 客户端库（如浏览器的 fetch、XMLHttpRequest，或工具如 curl）允许在 GET 请求中添加 Body。许多服务器框架（如 Express、Nginx、Apache）在处理 GET 请求时默认不解析 Body，甚至直接丢弃。即使可以带 Body，实际中不推荐，因为会引发兼容性和预期外的问题

##### 3、HTTP缓存技术

**（1）HTTP 缓存有哪些实现方式？**

HTTP 缓存是将 HTTP 响应的内容（HTML、图片、CSS、API 数据等）临时存储在某个地方（如浏览器内存、代理服务器），当下次发起相同请求时，直接使用缓存副本，而不是重新向服务器请求。

HTTP 缓存有两种实现方式，分别是**强制缓存和协商缓存**。

 **（2）什么是强制缓存？**

强制缓存是指在缓存未过期的情况下，客户端直接使用本地缓存的副本，无需向服务器发送任何请求。缓存的有效性由服务器预先指定的时间或规则决定。

**工作原理**

- 服务器通过响应头（如 `Cache-Control` 或 `Expires`）告诉客户端缓存的有效期。
- 在有效期内，客户端发起相同请求时，直接从缓存中读取数据，不联系服务器。

**关键头部字段**

- **Cache-Control: max-age**：
  - 指定缓存有效时间（单位：秒）。
  - 示例：`Cache-Control: max-age=3600` 表示缓存 1 小时。
- **Expires**：
  - 指定缓存的绝对过期时间。
  - 示例：`Expires: Mon, 03 Mar 2025 12:00:00 GMT`。
  - 注意：`Cache-Control` 优先级高于 `Expires`。

**流程**

1. 客户端首次请求：

   ```
   GET /logo.png HTTP/1.1
   Host: example.com
   ```

2. 服务器响应：

   ```
   HTTP/1.1 200 OK
   Cache-Control: max-age=3600
   Content-Type: image/png
   [图片数据]
   ```

3. 后续请求（1 小时内）：

   - 浏览器检查缓存未过期，直接返回本地副本，无网络请求。

**特点**

- **无需服务器交互**：完全依赖本地缓存。
- **高效**：减少网络请求，速度最快。
- **适用场景**：静态资源（如图片、CSS、JS），内容不常变化。

**缺点**

- 如果资源在有效期内更新，客户端无法感知，可能使用过时数据。

 **（3）什么是协商缓存？**

协商缓存是指在缓存过期或需要验证时，客户端向服务器发送请求，询问缓存的资源是否仍然有效。如果有效，服务器返回 304 状态码（Not Modified），客户端继续使用本地缓存；如果无效，服务器返回新数据。

**工作原理**

- 服务器通过响应头（如 `ETag` 或 `Last-Modified`）为资源提供标识或时间戳。
- 客户端后续请求时带上这些信息，服务器判断资源是否变化。

**关键头部字段**

- **ETag 和 If-None-Match**：
  - `ETag`：资源的唯一标识符（如 `"abc123"`）。
  - 客户端请求时带 `If-None-Match`，服务器比对后决定响应。
- **Last-Modified 和 If-Modified-Since**：
  - `Last-Modified`：资源最后修改时间。
  - 客户端请求时带 `If-Modified-Since`，服务器检查时间是否变化。

---

**1. 协商缓存的两种方式**

**第一种：基于 `Last-Modified` 和 `If-Modified-Since`**

- **定义**：

  - **`Last-Modified`**（响应头部）：服务器返回资源时，标示该资源的最后修改时间（如 `Last-Modified: Mon, 03 Mar 2025 10:00:00 GMT`）。
  - **`If-Modified-Since`**（请求头部）：客户端下次请求时带上之前收到的 `Last-Modified` 时间，用于询问服务器资源是否更新。

- **工作流程**：

  1. 首次请求：

     ```
     GET /logo.png HTTP/1.1
     ---
     HTTP/1.1 200 OK
     Last-Modified: Mon, 03 Mar 2025 10:00:00 GMT
     [图片数据]
     ```

  2. 缓存过期后再次请求：

     ```
     GET /logo.png HTTP/1.1
     If-Modified-Since: Mon, 03 Mar 2025 10:00:00 GMT
     ```

  3. 服务器对比：

     - 检查资源的当前修改时间与 `If-Modified-Since` 的时间。

     - **时间更新（更大）**：资源被修改，返回新数据（`200 OK`）。

       ```
       HTTP/1.1 200 OK
       Last-Modified: Mon, 03 Mar 2025 11:00:00 GMT
       [新图片数据]
       ```

     - **时间未变（等于或更小）**：资源未修改，返回 `304 Not Modified`。

       ```
       HTTP/1.1 304 Not Modified
       ```

- **特点**：

  - 基于时间戳对比，简单直观。
  - 客户端用缓存，节省带宽。

**第二种：基于 `ETag` 和 `If-None-Match`**

- **定义**：

  - **`ETag`**（响应头部）：服务器为资源生成一个唯一标识符（如 `"logo-v1"`），通常基于内容哈希或版本号。
  - **`If-None-Match`**（请求头部）：客户端下次请求时带上之前的 `ETag` 值，询问服务器资源是否变化。

- **工作流程**：

  1. 首次请求：

     ```
     GET /logo.png HTTP/1.1
     ---
     HTTP/1.1 200 OK
     ETag: "logo-v1"
     [图片数据]
     ```

  2. 缓存过期后再次请求：

     ```
     GET /logo.png HTTP/1.1
     If-None-Match: "logo-v1"
     ```

  3. 服务器对比：

     - 检查当前资源的 `ETag` 与 `If-None-Match` 的值。

     - **不匹配**：资源变化，返回新数据（`200 OK`）。

       ```
       HTTP/1.1 200 OK
       ETag: "logo-v2"
       [新图片数据]
       ```

     - **匹配**：资源未变，返回 `304 Not Modified`。

       ```
       HTTP/1.1 304 Not Modified
       ```

- **特点**：

  - 基于唯一标识，精确判断内容变化。
  - 不依赖时间戳。

2. **两种方式的对比**

- **基于时间（Last-Modified）**：
  - 依赖资源的修改时间。
  - 优点：简单，服务器易实现。
  - 缺点：时间可能不准确或粒度不足。

- **基于标识（ETag）**：
  - 依赖内容的唯一标识。
  - 优点：更精确，能检测内容是否真正变化。
  - 缺点：生成 `ETag` 可能增加服务器计算成本。

3. **`ETag` 优先级更高的原因**

- **问题**：如果响应同时携带 `Last-Modified` 和 `ETag`，客户端后续请求带上两组字段（`If-Modified-Since` 和 `If-None-Match`），服务器会优先检查 `ETag`。

- **原因**：`ETag` 解决了 `Last-Modified` 的以下局限：

  1. **时间误判**：
     - 文件未改动，但时间戳因操作（如移动、重命名）变化，导致客户端误认为资源更新。
     - 示例：文件内容不变，但 `Last-Modified` 变为新时间，触发不必要的 `200 OK`。
  2. **秒级粒度不足**：
     - `Last-Modified` 以秒为单位，若文件在 1 秒内多次修改，客户端无法感知。
     - `ETag` 可基于内容实时生成，精确到每次变化。
  3. **时间不可靠**：
     - 某些服务器（如分布式系统）无法精确获取文件修改时间，或时间同步有偏差。
     - `ETag` 直接反映内容，避开时间问题。

- **优先级逻辑**：

  - 服务器先比对 `ETag`：
    - 若 `If-None-Match` 与当前 `ETag` 不匹配，直接返回新数据。
    - 若匹配，再检查 `Last-Modified`（作为次级验证）。
  - 这样确保判断更准确，避免时间导致的误判。

- **示例**：

  ```
  GET /logo.png HTTP/1.1
  If-None-Match: "logo-v1"
  If-Modified-Since: Mon, 03 Mar 2025 10:00:00 GMT
  ---
  HTTP/1.1 200 OK
  ETag: "logo-v2"
  Last-Modified: Mon, 03 Mar 2025 11:00:00 GMT
  [新数据]
  ```

  - `ETag` 不匹配，表明内容变了，无需再看时间。

![image-20250304113138236](D:/interview/assets/image-20250304113138236.png)

##### 4、HTTP/1.1特性

HTTP 最突出的优点是「简单、灵活和易于扩展、应用广泛和跨平台」。

*1. 简单*

HTTP 基本的报文格式就是 `header + body`，头部信息也是 `key-value` 简单文本的形式，**易于理解**，降低了学习和使用的门槛。

```text
GET /index.html HTTP/1.1
Host: example.com
Accept: text/html

[Body 可为空]
```

*2. 灵活和易于扩展*

HTTP 协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员**自定义和扩充**。

同时 HTTP 由于是工作在应用层（ `OSI` 第七层），则它**下层可以随意变化**，比如：

- HTTPS 就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层；
- HTTP/1.1 和 HTTP/2.0 传输协议使用的是 TCP 协议，而到了 HTTP/3.0 传输协议改用了 UDP 协议。

*3. 应用广泛和跨平台*

互联网发展至今，HTTP 的应用范围非常的广泛，从台式机的浏览器到手机上的各种 APP，从看新闻、刷贴吧到购物、理财、吃鸡，HTTP 的应用遍地开花，同时天然具有**跨平台**的优越性。

**HTTP/1.1 的缺点有哪些？**

1.无状态

HTTP/1.1 是无状态协议，即服务器不保留客户端的先前请求信息，每条请求都被视为独立操作。

2.明文传输

HTTP/1.1 默认以明文（纯文本）传输数据，请求和响应的内容未加密。

3.不安全

HTTP/1.1 缺乏内置的安全机制，容易受到各种网络攻击。

**HTTP/1.1 的性能如何**？

1.长连接

**描述**：

- HTTP/1.0 默认每次请求后关闭 TCP 连接（Connection: close），HTTP/1.1 默认启用持久连接（Connection: keep-alive），允许在同一 TCP 连接上发送多个请求和响应。

**性能提升**：

- 减少了重复建立和关闭 TCP 连接的开销（包括三次握手和四次挥手）。
- 降低了网络延迟和服务器负载。

**示例**：

- 请求页面中的 HTML、CSS、图片时，复用一个连接而不是为每个资源建立新连接。

![image-20250304151046499](D:/interview/assets/image-20250304151046499.png)

2.管道网络传输

**描述**：

- 客户端可以在不等待前一个响应的情况下连续发送多个请求。即可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以**减少整体的响应时间。**

**性能提升**：

- 理论上减少了请求间的等待时间，提高了并发效率。

**示例**：

- 客户端同时发送 GET /page.html 和 GET /style.css，无需等待第一个响应。

![image-20250304151223997](D:/interview/assets/image-20250304151223997.png)

3.队头阻塞

**描述**：

- 即使启用了持久连接和管道化，HTTP/1.1 的请求和响应仍是串行的。前一个请求未完成，后续请求被阻塞。

**影响**：

- 如果某个资源（如大图片）加载缓慢，所有后续请求（如 JS、CSS）必须等待，导致页面渲染延迟。

**管道化的局限**：

- 管道化虽允许连续发送请求，但响应仍按序返回。若首个响应延迟，后面全部受阻。
- 许多浏览器默认禁用管道化（因服务器支持不一致和复杂性），使其失效。

**示例**：

- 请求 5 个资源，第 1 个耗时 5 秒，后 4 个即使只需 1 秒，也要等到第 5 秒才能完成。

##### 5、HTTP与HTTPS

**（1） HTTP 与 HTTPS 有哪些区别？**

- HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
- HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
- 两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。
- HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

 **（2）HTTPS 解决了 HTTP 的哪些问题？**

HTTP**S** 在 HTTP 与 TCP 层之间加入了 `SSL/TLS` 协议，可以很好的解决了风险：

![image-20250304152645053](D:/interview/assets/image-20250304152645053.png)

**HTTPS 是如何解决上面的风险的？**

- **混合加密**的方式实现信息的**机密性**，解决了窃听的风险。
- **摘要算法**的方式来实现**完整性**，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。
- 将服务器公钥放入到**数字证书**中，解决了冒充的风险。

**（a）混合加密**

**原理：**

HTTPS 使用 **混合加密** 机制，结合了对称加密和非对称加密的优点，确保数据在传输过程中的机密性。

**方式：**

1. 在 SSL/TLS 握手阶段，客户端与服务器通过非对称加密协商一个临时的对称密钥（会话密钥）。
2. 后续的数据传输使用这个对称密钥进行加密。

>举例：
>
>想象你在寄一封信，先用一个只有你和收件人知道的密码（对称密钥）加密信件内容，但这个密码是通过一个特殊的锁（非对称加密）安全交给对方的，窃听者即使拿到信也打不开。

![image-20250304153014900](D:/interview/assets/image-20250304153014900.png)

**（b）摘要算法 + 数字签名**

**原理：**

HTTPS 使用 **摘要算法**（如 MD5、SHA-256）生成数据的“指纹”（即哈希值），并结合数字签名机制，确保数据在传输过程中未被篡改。

为了保证传输的内容不被篡改，我们需要对内容计算出一个「指纹」，然后同内容一起传输给对方。

对方收到后，先是对内容也计算出一个「指纹」，然后跟发送方发送的「指纹」做一个比较，如果「指纹」相同，说明内容没有被篡改，否则就可以判断出内容被篡改了。

那么，在计算机里会**用摘要算法（哈希函数）来计算出内容的哈希值**，也就是内容的「指纹」，这个**哈希值是唯一的，且无法通过哈希值推导出内容**。

![image-20250304153404702](D:/interview/assets/image-20250304153404702.png)

通过哈希算法可以确保内容不会被篡改，**但是并不能保证「内容 + 哈希值」不会被中间人替换，因为这里缺少对客户端收到的消息是否来源于服务端的证明**。

那为了避免这种情况，计算机里会用**非对称加密算法**来解决，共有两个密钥：

- 一个是公钥，这个是可以公开给所有人的；
- 一个是私钥，这个必须由本人管理，不可泄露。

这两个密钥可以**双向加解密**的，比如可以用公钥加密内容，然后用私钥解密，也可以用私钥加密内容，公钥解密内容。

流程的不同，意味着目的也不相同：

- **公钥加密，私钥解密**。这个目的是为了**保证内容传输的安全**，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容；
- **私钥加密，公钥解密**。这个目的是为了**保证消息不会被冒充**，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。

![image-20250304154518573](D:/interview/assets/image-20250304154518573.png)

**（c）数字证书**

**定义**：数字证书是一种电子文档，包含网站的公钥、域名、证书颁发机构（CA）信息等，并由CA机构用私钥签名，以证明其真实性。

![image-20250304154915592](D:/interview/assets/image-20250304154915592.png)

**（3）HTTPS是如何建立连接的？期间交互了什么？**

SSL/TLS 协议基本流程：

- 客户端向服务器索要并验证服务器的公钥。
- 双方协商生产「会话秘钥」。
- 双方采用「会话秘钥」进行加密通信。

前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段。

TLS 的「握手阶段」涉及**四次**通信，使用不同的密钥交换算法，TLS 握手流程也会不一样的，现在常用的密钥交换算法有两种：[RSA 算法 (opens new window)](https://xiaolincoding.com/network/2_http/https_rsa.html)和 [ECDHE 算法 (opens new window)](https://xiaolincoding.com/network/2_http/https_ecdhe.html)。

基于 RSA 算法的 TLS 握手过程比较容易理解，所以这里先用这个给大家展示 TLS 握手过程，如下图：

![image-20250304161155132](D:/interview/assets/image-20250304161155132.png)

TLS 协议建立的详细流程：

*1. ClientHello*

首先，由客户端向服务器发起加密通信请求，也就是 `ClientHello` 请求。

在这一步，客户端主要向服务器发送以下信息：

（1）客户端支持的 TLS 协议版本，如 TLS 1.2 版本。

（2）客户端生产的随机数（`Client Random`），后面用于生成「会话秘钥」条件之一。

（3）客户端支持的密码套件列表，如 RSA 加密算法。

*2. SeverHello*

服务器收到客户端请求后，向客户端发出响应，也就是 `SeverHello`。服务器回应的内容有如下内容：

（1）确认 TLS 协议版本，如果浏览器不支持，则关闭加密通信。

（2）服务器生产的随机数（`Server Random`），也是后面用于生产「会话秘钥」条件之一。

（3）确认的密码套件列表，如 RSA 加密算法。

（4）服务器的数字证书。

*3.客户端回应*

客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。

如果证书没有问题，客户端会**从数字证书中取出服务器的公钥**，然后使用它加密报文，向服务器发送如下信息：

（1）一个随机数（`pre-master key`）。该随机数会被服务器公钥加密。

（2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。

（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。

上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。

**服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」**。

*4. 服务器的最后回应*

服务器收到客户端的第三个随机数（`pre-master key`）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。

然后，向客户端发送最后的信息：

（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。

（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。

至此，整个 TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。

**（4）HTTPS 的应用数据是如何保证完整性的？**

- TLS 握手协议就是我们前面说的 TLS 四次握手的过程，负责协商加密算法和生成对称密钥，后续用此密钥来保护应用程序数据（即 HTTP 数据）；
- TLS 记录协议负责保护应用程序数据并验证其完整性和来源，所以对 HTTP 数据加密是使用记录协议；

TLS 记录协议主要负责消息（HTTP 数据）的压缩，加密及数据的认证，过程如下图：

![image-20250304162924146](D:/interview/assets/image-20250304162924146.png)

具体过程如下：

- 首先，消息被分割成多个较短的片段,然后分别对每个片段进行压缩。
- 接下来，经过压缩的片段会被**加上消息认证码（MAC 值，这个是通过哈希算法生成的），这是为了保证完整性，并进行数据的认证**。通过附加消息认证码的 MAC 值，可以识别出篡改。与此同时，为了防止重放攻击，在计算消息认证码时，还加上了片段的编码。
- 再接下来，经过压缩的片段再加上消息认证码会一起通过对称密码进行加密。
- 最后，上述经过加密的数据再加上由数据类型、版本号、压缩后的长度组成的报头就是最终的报文数据。

记录协议完成后，最终的报文数据将传递到传输控制协议 (TCP) 层进行传输。

**（5） HTTPS 一定安全可靠吗？**

具体过程如下：

- 客户端向服务端发起 HTTPS 建立连接请求时，然后被「假基站」转发到了一个「中间人服务器」，接着中间人向服务端发起 HTTPS 建立连接请求，此时客户端与中间人进行 TLS 握手，中间人与服务端进行 TLS 握手；
- 在客户端与中间人进行 TLS 握手过程中，中间人会发送自己的公钥证书给客户端，**客户端验证证书的真伪**，然后从证书拿到公钥，并生成一个随机数，用公钥加密随机数发送给中间人，中间人使用私钥解密，得到随机数，此时双方都有随机数，然后通过算法生成对称加密密钥（A），后续客户端与中间人通信就用这个对称加密密钥来加密数据了。
- 在中间人与服务端进行 TLS 握手过程中，服务端会发送从 CA 机构签发的公钥证书给中间人，从证书拿到公钥，并生成一个随机数，用公钥加密随机数发送给服务端，服务端使用私钥解密，得到随机数，此时双方都有随机数，然后通过算法生成对称加密密钥（B），后续中间人与服务端通信就用这个对称加密密钥来加密数据了。
- 后续的通信过程中，中间人用对称加密密钥（A）解密客户端的 HTTPS 请求的数据，然后用对称加密密钥（B）加密 HTTPS 请求后，转发给服务端，接着服务端发送 HTTPS 响应数据给中间人，中间人用对称加密密钥（B）解密 HTTPS 响应数据，然后再用对称加密密钥（A）加密后，转发给客户端。

从客户端的角度看，其实并不知道网络中存在中间人服务器这个角色。那么中间人就可以解开浏览器发起的 HTTPS 请求里的数据，也可以解开服务端响应给浏览器的 HTTPS 响应数据。相当于，中间人能够 “偷看” 浏览器与服务端之间的 HTTPS 请求和响应的数据。

但是要发生这种场景是有前提的，前提是用户点击接受了中间人服务器的证书。

中间人服务器与客户端在 TLS 握手过程中，实际上发送了自己伪造的证书给浏览器，而这个伪造的证书是能被浏览器（客户端）识别出是非法的，于是就会提醒用户该证书存在问题。

所以，**HTTPS 协议本身到目前为止还是没有任何漏洞的，即使你成功进行中间人攻击，本质上是利用了客户端的漏洞（用户点击继续访问或者被恶意导入伪造的根证书），并不是 HTTPS 不够安全**。

##### 6、HTTP的演变

**（1） HTTP/1.1 相比 HTTP/1.0 提高了什么性能？**

HTTP/1.1 相比 HTTP/1.0 性能上的改进：

- 使用长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。
- 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

但 HTTP/1.1 还是有性能瓶颈：

- 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 `Body` 的部分；
- 发送冗长的首部。每次互相发送相同的首部造成的浪费较多；
- 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；
- 没有请求优先级控制；
- 请求只能从客户端开始，服务器只能被动响应。

**（2）HTTP/2做了什么优化**

HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。

![image-20250304192417368](D:/interview/assets/image-20250304192417368.png)

那 HTTP/2 相比 HTTP/1.1 性能上的改进：

1. **头部压缩 (Header Compression)**

- **HTTP/1.1**: 头部信息以纯文本传输，重复字段（如 User-Agent、Cookie 等）在每个请求中都完整发送，浪费带宽，尤其在频繁请求时开销显著。
- **HTTP/2**: 使用 HPACK 压缩算法，在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就**提高速度**了。。
- **性能提升**: 减少了冗余传输，特别是在移动网络和高延迟环境下，节省带宽并加速请求处理。

2. **二进制格式 (Binary Format)**

- **HTTP/1.1**: 文本协议，解析复杂且容易出错，效率较低。
- **HTTP/2**: 采用二进制协议，将数据分为帧（如头部帧、数据帧），结构化传输，解析更快且更可靠。
- **性能提升**: 降低了客户端和服务器的解析开销，减少了错误处理时间，提升了传输效率，尤其对机器处理更友好。

3. **并发传输 (Multiplexing / Concurrent Transmission)**

- **HTTP/1.1**: 即使支持管道化，仍有队头阻塞问题，一个慢请求会拖延后续请求，且并发通常需要多个 TCP 连接。
- **HTTP/2**: 在单一 TCP 连接上实现多路复用，通过流（Stream）并行传输多个请求和响应，互不干扰。

![image-20250304192817612](D:/interview/assets/image-20250304192817612.png)

从上图可以看到，1 个 TCP 连接包含多个 Stream，Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成。Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）。

**针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，也就是 HTTP/2 可以并行交错地发送请求和响应**。

- **性能提升**: 消除了队头阻塞，提高了资源加载效率，特别是在高并发场景（如加载包含数十个资源的网页）下，延迟显著降低。

4. **服务器主动推送资源 (Server Push)**

- **HTTP/1.1**: 客户端必须逐一请求资源，服务器无法主动发送，增加了多次往返时间（RTT）。

- **HTTP/2**: 服务器可以预测客户端需求（如推送 HTML 引用的 CSS 或 JS），在响应主请求时一并推送相关资源。

- 客户端和服务器**双方都可以建立 Stream**， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。

  比如下图，Stream 1 是客户端向服务端请求的资源，属于客户端建立的 Stream，所以该 Stream 的 ID 是奇数（数字 1）；Stream 2 和 4 都是服务端主动向客户端推送的资源，属于服务端建立的 Stream，所以这两个 Stream 的 ID 是偶数（数字 2 和 4）。

![image-20250304193133355](D:/interview/assets/image-20250304193133355.png)

- **性能提升**: 减少了客户端等待额外资源的时间，加速页面渲染，尤其对首次加载体验优化明显。

> HTTP/2 有什么缺陷？
>
> HTTP/2 通过 Stream 的并发能力，解决了 HTTP/1 队头阻塞的问题，看似很完美了，但是 HTTP/2 还是存在“队头阻塞”的问题，只不过问题不是在 HTTP 这一层面，而是在 TCP 这一层。
>
> **HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。**

 **（3）HTTP/3 做了哪些优化？**

**HTTP/2**: 依赖 TCP，TCP 的可靠性和顺序交付特性导致队头阻塞（Head-of-Line Blocking），一个数据包丢失会阻塞整个连接。

**HTTP/3**: 使用 QUIC，基于 UDP，QUIC 在应用层实现了可靠性、流量控制和拥塞控制。每个流独立传输，某个流的数据包丢失不会影响其他流。

**优化效果**: 消除了 TCP 层面的队头阻塞，显著降低延迟，尤其在丢包率高的网络（如移动网络）中表现更好。

![image-20250304193521511](D:/interview/assets/image-20250304193521511.png)

QUIC 有以下 3 个特点。

- 无队头阻塞
- 更快的连接建立
- 连接迁移

1. **无队头阻塞 (No Head-of-Line Blocking)**

- **问题背景**: 在 TCP（HTTP/2 使用）中，所有数据按顺序传输，如果某个数据包丢失，整个连接必须等待该包重传，导致后续数据被阻塞（即队头阻塞）。
- **QUIC 的改进**: QUIC 在 UDP 上实现多路复用（Multiplexing），将数据分成独立的“流”（Stream）。每个流单独管理传输和重传，一个流的丢包不会影响其他流。
- **具体例子**: 假设一个网页加载 HTML、CSS 和图片，若图片流的某个包丢失，HTML 和 CSS 的传输仍可继续，不会被拖延。
- **优势**: 大幅降低延迟，尤其在丢包率高的网络（如移动网络或跨国连接）中，提升了并发传输效率。

![image-20250304193809772](D:/interview/assets/image-20250304193809772.png)

2. **更快的连接建立 (Faster Connection Establishment)**

- **问题背景**: TCP 需要三次握手（1 RTT），加上 TLS 加密的握手（1-2 RTT），总计 2-3 RTT 才能开始数据传输，延迟较高。

- QUIC 的改进

  : QUIC 将传输层和加密层（TLS 1.3）融合，减少握手步骤：

  - **首次连接**: 合并 QUIC 和 TLS 握手，通常只需 1 RTT。
  - **后续连接**: 支持“0-RTT”，客户端使用之前缓存的密钥直接发送数据，无需握手。

![image-20250304194031881](D:/interview/assets/image-20250304194031881.png)

- **具体例子**: 用户再次访问某网站时，浏览器可立即发送请求，无需等待服务器确认，类似“敲门即入”。
- **优势**: 显著缩短连接建立时间，尤其对短连接（如 API 请求）和首次页面加载体验提升明显。

3. **连接迁移 (Connection Migration)**

- **问题背景**: TCP 连接基于四元组（源 IP、源端口、目标 IP、目标端口），网络切换（如从 Wi-Fi 到 4G）会导致 IP 变化，连接中断，需重新握手。

![image-20250304194203923](D:/interview/assets/image-20250304194203923.png)

- **QUIC 的改进**: QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID** 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。QUIC 使用唯一的连接 ID（Connection ID）标识连接，而非依赖 IP 和端口。网络环境变化时，连接 ID 保持不变，客户端和服务器可继续通信。
- **具体例子**: 用户在手机上看视频，从家里 Wi-Fi 切换到户外移动数据，视频播放不中断。
- **优势**: 提供无缝的网络切换体验，特别适合移动设备和不稳定网络环境。



### 3.5

#### 2.2 HTTP/1.1优化<a name="2.2"></a>

我们可以从下面这三种优化思路来优化 HTTP/1.1 协议：

- *尽量避免发送 HTTP 请求*；
- *在需要发送 HTTP 请求时，考虑如何减少请求次数*；
- *减少服务器的 HTTP 响应的数据大小*；

##### 1、尽量避免发送 HTTP 请求；

这个思路的核心是减少客户端向服务器发送请求的频率，因为在 HTTP/1.1 中，每个请求都会带来额外的开销（如 TCP 连接建立、头部数据传输等）。可以通过以下方法实现：

所以，避免发送 HTTP 请求的方法就是通过**缓存技术**，HTTP 设计者早在之前就考虑到了这点，因此 HTTP 协议的头部有不少是针对缓存的字段。

那缓存是如何做到的呢？

客户端会把第一次请求以及响应的数据保存在本地磁盘上，其中将请求的 URL 作为 key，而响应作为 value，两者形成映射关系。

这样当后续发起相同的请求时，就可以先在**本地磁盘**上通过 key 查到对应的 value，也就是响应，如果找到了，就直接从本地读取该响应。毋庸置疑，读取本地磁盘的速度肯定比网络请求快得多，如下图：

![image-20250305094157692](D:/interview/assets/image-20250305094157692.png)

万一缓存的响应不是最新的，而客户端并不知情，那么该怎么办呢？

放心，这个问题 HTTP 设计者早已考虑到。

所以，服务器在发送 HTTP 响应时，会估算一个**过期的时间**，并把这个信息放到响应头部中，这样客户端在查看响应头部的信息时，一旦发现缓存的响应是过期的，则就会重新发送网络请求。

如果客户端从第一次请求得到的响应头部中发现该响应过期了，客户端重新发送请求，假设服务器上的资源并没有变更，还是老样子，那么你觉得还要在服务器的响应带上这个资源吗？

不需要！
 HTTP 的条件请求机制正是为此设计的。如果服务器确认资源未变更，只需返回 304 状态码，告诉客户端“资源没变，用你本地的缓存吧”。这样既节省了带宽，又减少了传输时间，完美契合了“减少服务器 HTTP 响应的数据大小”的优化思路。

只需要客户端在重新发送请求时，在请求的 `Etag` 头部带上第一次请求的响应头部中的摘要，这个摘要是唯一标识响应的资源，当服务器收到请求后，会将本地资源的摘要与请求中的摘要做个比较。

如果不同，那么说明客户端的缓存已经没有价值，服务器在响应中带上最新的资源。

如果相同，说明客户端的缓存还是可以继续使用的，那么服务器**仅返回不含有包体的 `304 Not Modified` 响应**，告诉客户端仍然有效，这样就可以减少响应资源在网络中传输的延时，如下图：

![image-20250305095543752](D:/interview/assets/image-20250305095543752.png)

##### 2、在需要发送 HTTP 请求时，考虑如何减少请求次数；

减少 HTTP 请求次数自然也就提升了 HTTP 性能，可以从这 3 个方面入手：

（1）减少重定向请求次数；

重定向：当客户端发送一个 HTTP 请求时，服务器可能会发现请求的资源位置已变更，或者需要额外的条件（如登录验证），这时服务器会返回一个 3xx 状态码，并通过 Location 头部指定新的目标地址。客户端收到后，会自动或手动（视情况而定）向新地址发起请求。

那么，如果重定向请求越多，那么客户端就要多次发起 HTTP 请求，每一次的 HTTP 请求都得经过网络，这无疑会越降低网络性能。

另外，服务端这一方往往不只有一台服务器，比如源服务器上一级是代理服务器，然后代理服务器才与客户端通信，这时客户端重定向就会导致客户端与代理服务器之间需要 2 次消息传递，如下图：

![image-20250305095950233](D:/interview/assets/image-20250305095950233.png)

如果**重定向的工作交由代理服务器完成，就能减少 HTTP 请求次数了**，如下图：

![image-20250305100008145](D:/interview/assets/image-20250305100008145.png)

除了 `302` 重定向响应码，还有其他一些重定向的响应码，你可以从下图看到：

![image-20250305100113606](D:/interview/assets/image-20250305100113606.png)

（2）合并请求；

HTTP/1.1 的一个瓶颈是它不支持真正的多路复用（Multiplexing），多个资源请求需要排队或建立多个连接。通过将多个小请求合并为一个大请求，可以减少请求次数，缓解这一问题。

另外由于 HTTP/1.1 是请求响应模型，如果第一个发送的请求，未收到对应的响应，那么后续的请求就不会发送（PS：HTTP/1.1 管道模式是默认不使用的，所以讨论 HTTP/1.1 的队头阻塞问题，是不考虑管道模式的），于是为了防止单个请求的阻塞，所以**一般浏览器会同时发起 5-6 个请求，每一个请求都是不同的 TCP 连接**，那么如果合并了请求，也就会**减少 TCP 连接的数量，因而省去了 TCP 握手和慢启动过程耗费的时间**。

**合并请求的方式就是合并资源，以一个大资源的请求替换多个小资源的请求**。

但是这样的合并请求会带来新的问题，**当大资源中的某一个小资源发生变化后，客户端必须重新下载整个完整的大资源文件**，这显然带来了额外的网络消耗。

（3）延迟发送请求；

并非所有资源都需要在页面加载时立即请求。通过推迟非关键资源的请求，可以优先加载核心内容，提升用户感知性能（Perceived Performance）。这种方法特别适合减少首屏加载时间。

不要一口气吃成大胖子，一般 HTML 里会含有很多 HTTP 的 URL，当前不需要的资源，我们没必要也获取过来，于是可以通过「**按需获取**」的方式，来减少第一时间的 HTTP 请求次数。

请求网页的时候，没必要把全部资源都获取到，而是只获取当前用户所看到的页面资源，当用户向下滑动页面的时候，再向服务器获取接下来的资源，这样就达到了延迟发送请求的效果。

##### 3、减少服务器的 HTTP 响应的数据大小；

对于 HTTP 的请求和响应，通常 HTTP 的响应的数据大小会比较大，也就是服务器返回的资源会比较大。

于是，我们可以考虑对响应的资源进行**压缩**，这样就可以减少响应的数据大小，从而提高网络传输的效率。

压缩的方式一般分为 2 种，分别是：

- *无损压缩*；
- *有损压缩*；

（1）无损压缩

**定义**

无损压缩是一种压缩方法，在压缩和解压过程中不会丢失任何原始数据。压缩后的数据可以完全还原为原始状态，保证信息的完整性。

**原理**

无损压缩通过识别和消除数据中的冗余部分来减少数据大小，而不删除任何实际内容。常见的冗余包括重复模式、统计规律等。

**实现方式**

首先，我们针对代码的语法规则进行压缩，因为通常代码文件都有很多换行符或者空格，这些是为了帮助程序员更好的阅读，但是机器执行时并不要这些符，把这些多余的符号给去除掉。

接下来，就是无损压缩了，需要对原始资源建立统计模型，利用这个统计模型，将常出现的数据用较短的二进制比特序列表示，将不常出现的数据用较长的二进制比特序列表示，生成二进制比特序列一般是「霍夫曼编码」算法。

（2）有损压缩

**定义**

有损压缩通过丢弃部分“次要”数据来大幅减少数据大小，解压后无法完全还原原始数据，但通常保留人类感知上最重要的部分。

**原理**

有损压缩利用人类感官的局限性，去除那些不易察觉的细节。例如，耳朵听不到某些高频声音，眼睛难以区分细微颜色变化，这些都可以被丢弃。

**实现方式：**

可以通过 HTTP 请求头部中的 `Accept` 字段里的「 q 质量因子」，告诉服务器期望的资源质量。

```text
Accept: audio/*; q=0.2, audio/basic
```



### 3.6

#### 2.3 HTTPS RSA握手<a name="2.3"></a>

##### 1、TSL握手过程

HTTP 由于是明文传输，所谓的明文，就是说客户端与服务端通信的信息都是肉眼可见的，随意使用一个抓包工具都可以截获通信的内容。

HTTP**S** 在 HTTP 与 TCP 层之间加入了 TLS 协议，来解决上述的风险。

![image-20250306093349602](D:/interview/assets/image-20250306093349602.png)

**HTTP 的主要风险**

1. **数据明文传输**：HTTP 的数据以明文形式传输，容易被中间人（MITM，Man-in-the-Middle）拦截和窃听，例如在公共 Wi-Fi 上嗅探用户密码或敏感信息。
2. **数据篡改**：HTTP 无法保证数据的完整性，攻击者可以在传输过程中修改数据（如篡改网页内容或请求参数），用户和服务器无法察觉。
3. **身份伪装**：HTTP 没有提供可靠的身份验证机制，客户端无法确认服务器的真实性，可能连接到恶意伪装的服务器（如钓鱼网站）。

**TLS 如何解决这些风险**

TLS 通常与 HTTP 结合使用，形成 HTTPS（HTTP Secure），通过以下方式解决上述问题：

1. **加密通信（解决数据明文传输）**

- **机制**：TLS 使用对称加密和非对称加密相结合的方式。客户端和服务器通过握手过程协商一个会话密钥（对称加密密钥），然后用这个密钥加密所有传输的数据。
- **效果**：即使数据被拦截，攻击者也无法解密内容。例如，用户输入的密码或银行卡号在传输时是加密的，无法被直接读取。
- **技术细节**：握手阶段通常使用非对称加密（如 RSA 或 ECDHE）交换密钥，而数据传输则使用更高效的对称加密算法（如 AES）。

2. **数据完整性保护（解决数据篡改）**

- **机制**：TLS 使用消息认证码（MAC，Message Authentication Code）或 HMAC（基于哈希的消息认证码）来验证数据的完整性。每次传输的数据都会附带一个校验值，确保数据未被篡改。
- **效果**：如果攻击者在传输过程中修改了数据，接收端会检测到校验值不匹配，从而拒绝接受被篡改的数据。例如，攻击者无法在用户请求中偷偷插入恶意代码而不被发现。

3. **身份认证（解决身份伪装）**

- **机制**：TLS 通过数字证书（由受信任的证书颁发机构 CA 签发）验证服务器的身份。客户端在握手时会检查服务器的证书是否有效、未过期，并且与域名匹配。
- **效果**：用户可以确信他们连接的是真实的服务器，而不是伪装的恶意站点。例如，当你访问 https://www.google.com 时，TLS 确保你连接的是谷歌的服务器，而不是钓鱼网站。
- **技术细节**：证书基于公钥基础设施（PKI），使用非对称加密验证服务器身份，客户端信任的 CA 根证书预装在浏览器或操作系统中。

可见，有了 TLS 协议，能保证 HTTP 通信是安全的了，那么在进行 HTTP 通信前，需要先进行 TLS 握手。TLS 的握手过程，如下图：

![image-20250306094331211](D:/interview/assets/image-20250306094331211.png)

**TLS 握手过程简述**

TLS 的核心是握手过程，它在建立安全连接时完成以下步骤：

1. **客户端 hello**：客户端发送支持的加密算法和协议版本。
2. **服务器 hello**：服务器选择加密算法并返回数字证书。
3. **证书验证**：客户端验证服务器证书的合法性。
4. **密钥交换**：双方协商生成会话密钥。
5. **完成握手**：双方确认连接加密，开始安全通信。

##### 2、RSA握手过程

传统的 TLS 握手基本都是使用 RSA 算法来实现密钥交换的，在将 TLS 证书部署服务端时，证书文件其实就是服务端的公钥，会在 TLS 握手阶段传递给客户端，而服务端的私钥则一直留在服务端，一定要确保私钥不能被窃取。

RSA 握手的核心是利用非对称加密（RSA 算法）来安全地交换对称加密密钥（即会话密钥）。非对称加密使用一对密钥：

- **公钥**：用于加密数据，公开分发。
- **私钥**：用于解密数据，仅由服务器持有。

客户端用服务器的公钥加密会话密钥，服务器用私钥解密后获得相同的密钥，双方随后使用这个对称密钥进行高效的数据加密通信。

![image-20250306100520641](D:/interview/assets/image-20250306100520641.png)

**（1）TSL第一次握手（客户端 → 服务器）**

客户端首先会发一个「**Client Hello**」消息，字面意思我们也能理解到，这是跟服务器「打招呼」。

![image-20250306100650049](D:/interview/assets/image-20250306100650049.png)

消息里面有客户端使用的 TLS 版本号、支持的密码套件列表，以及生成的**随机数（\*Client Random\*）**，这个随机数会被服务端保留，它是生成对称加密密钥的材料之一。

**（2）TSL第二次握手（服务器 → 客户端）**

当服务端收到客户端的「Client Hello」消息后，会确认 TLS 版本号是否支持，和从密码套件列表中选择一个密码套件，以及生成**随机数（\*Server Random\*)**

接着，返回「**Server Hello**」消息，消息里面有服务器确认的 TLS 版本号，也给出了随机数（Server Random），然后从客户端的密码套件列表选择了一个合适的密码套件。

![image-20250306100939217](D:/interview/assets/image-20250306100939217.png)

可以看到，服务端选择的密码套件是 “Cipher Suite: TLS_RSA_WITH_AES_128_GCM_SHA256”。

**TLS_RSA_WITH_AES_128_GCM_SHA256** 表示：

- 使用 RSA 算法进行密钥交换。
- 使用 128 位密钥的 AES 加密算法（GCM 模式）来保护数据的机密性和完整性。
- 使用 SHA-256 哈希算法进一步增强数据完整性校验。

就前面这两个客户端和服务端相互「打招呼」的过程，客户端和服务端就已确认了 TLS 版本和使用的密码套件，而且你可能发现客户端和服务端都会各自生成一个随机数，并且还会把随机数传递给对方。

那这个随机数有啥用呢？其实这两个随机数是后续作为生成「会话密钥」的条件，所谓的会话密钥就是数据传输时，所使用的对称加密密钥。

然后，服务端为了证明自己的身份，会发送「**Server Certificate**」给客户端，这个消息里含有数字证书。

随后，服务端发了「**Server Hello Done**」消息，目的是告诉客户端，我已经把该给你的东西都给你了，本次打招呼完毕。

**客户端验证证书**

（i）**数字证书和 CA 机构**

在说校验数字证书是否可信的过程前，我们先来看看数字证书是什么，一个数字证书通常包含了：

- 公钥；
- 持有者信息；
- 证书认证机构（CA）的信息；
- CA 对这份文件的数字签名及使用的算法；
- 证书有效期；
- 还有一些其他额外信息；

那数字证书的作用，是用来认证公钥持有者的身份，以防止第三方进行冒充。说简单些，证书就是用来告诉客户端，该服务端是否是合法的，因为只有证书合法，才代表服务端身份是可信的。

我们用证书来认证公钥持有者的身份（服务端的身份），那证书又是怎么来的？又该怎么认证证书呢？

为了让服务端的公钥被大家信任，服务端的证书都是由 CA （*Certificate Authority*，证书认证机构）签名的，CA 就是网络世界里的公安局、公证中心，具有极高的可信度，所以由它来给各个公钥签名，信任的一方签发的证书，那必然证书也是被信任的。

之所以要签名，是因为签名的作用可以避免中间人在获取证书时对证书内容的篡改。

（ii） **数字证书签发和验证流程**

![image-20250306102110867](D:/interview/assets/image-20250306102110867.png)

CA 签发证书的过程，如上图左边部分：

- 首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值；
- 然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名；
- 最后将 Certificate Signature 添加在文件证书上，形成数字证书；

客户端校验服务端的数字证书的过程，如上图右边部分：

- 首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；
- 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ；
- 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。

**（iii）证书链**

但事实上，证书的验证过程中还存在一个证书信任链的问题，因为我们向 CA 申请的证书一般不是根证书签发的，而是由中间证书签发的，比如百度的证书，从下图你可以看到，证书的层级有三级：

![image-20250306102640600](D:/interview/assets/image-20250306102640600.png)

对于这种三级层级关系的证书的验证过程如下：

- 客户端收到 baidu.com 的证书后，发现这个证书的签发者不是根证书，就无法根据本地已有的根证书中的公钥去验证 baidu.com 证书是否可信。于是，客户端根据 baidu.com 证书中的签发者，找到该证书的颁发机构是 “GlobalSign Organization Validation CA - SHA256 - G2”，然后向 CA 请求该中间证书。
- 请求到证书后发现 “GlobalSign Organization Validation CA - SHA256 - G2” 证书是由 “GlobalSign Root CA” 签发的，由于 “GlobalSign Root CA” 没有再上级签发机构，说明它是根证书，也就是自签证书。应用软件会检查此证书有否已预载于根证书清单上，如果有，则可以利用根证书中的公钥去验证 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，如果发现验证通过，就认为该中间证书是可信的。
- “GlobalSign Organization Validation CA - SHA256 - G2” 证书被信任后，可以使用 “GlobalSign Organization Validation CA - SHA256 - G2” 证书中的公钥去验证 baidu.com 证书的可信性，如果验证通过，就可以信任 baidu.com 证书。

在这四个步骤中，最开始客户端只信任根证书 GlobalSign Root CA 证书的，然后 “GlobalSign Root CA” 证书信任 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，而 “GlobalSign Organization Validation CA - SHA256 - G2” 证书又信任 baidu.com 证书，于是客户端也信任 baidu.com 证书。

总括来说，由于用户信任 GlobalSign，所以由 GlobalSign 所担保的 baidu.com 可以被信任，另外由于用户信任操作系统或浏览器的软件商，所以由软件商预载了根证书的 GlobalSign 都可被信任。

**（3）TSL第三次握手（客户端 → 服务器）**

接着，客户端就会生成一个新的**随机数 (\*pre-master\*)**，用服务器的 RSA 公钥加密该随机数，通过「**Client Key Exchange**」消息传给服务端。

服务端收到后，用 RSA 私钥解密，得到客户端发来的随机数 (pre-master)。

至此，**客户端和服务端双方都共享了三个随机数，分别是 Client Random、Server Random、pre-master**。

于是，双方根据已经得到的三个随机数，生成**会话密钥（Master Secret）**，它是对称密钥，用于对后续的 HTTP 请求/响应的数据加解密。

生成完「会话密钥」后，然后客户端发一个「**Change Cipher Spec**」，告诉服务端开始使用加密方式发送消息。

然后，客户端再发一个「**Encrypted Handshake Message（Finishd）**」消息，把之前所有发送的数据做个**摘要**，再用会话密钥（master secret）加密一下，让服务器做个验证，验证加密通信「是否可用」和「之前握手信息是否有被中途篡改过」。

**（4）TSL第四次握手（服务器 → 客户端）**

服务器也是同样的操作，发「**Change Cipher Spec**」和「**Encrypted Handshake Message**」消息，如果双方都验证加密和解密没问题，那么握手正式完成。

最后，就用「会话密钥」加解密 HTTP 请求和响应了。

##### 3、RSA算法的缺陷

**缺乏前向保密（Perfect Forward Secrecy, PFS）**

- 缺陷描述：
  - 在 TLS 中，如果使用 RSA 进行密钥交换（如 TLS_RSA_WITH_*），客户端用服务端的 RSA 公钥加密预主密钥（Pre-Master Secret），服务端用私钥解密。如果服务端的私钥未来被泄露，攻击者可以解密之前记录的所有会话数据。
- 原因：
  - RSA 密钥交换依赖静态密钥对（公钥和私钥长期不变），不像 ECDHE（临时椭圆曲线 Diffie-Hellman）每次握手生成新密钥。
- 影响：
  - 缺乏前向保密，历史通信的机密性无法保障。
- 解决方法：
  - 使用支持 PFS 的算法（如 ECDHE），现代 TLS 1.3 已废弃 RSA 密钥交换。



### 3.7

#### 2.4 HTTPS ECDHE 握手<a name="2.4"></a>

##### 1、离散对数

离散对数（Discrete Logarithm）是密码学中一个核心的数学问题，特别是在基于椭圆曲线（ECC）或有限域的加密算法中，比如 ECDHE（Elliptic Curve Diffie-Hellman Ephemeral）。简单来说，离散对数是指数运算的逆运算，但由于其在离散数学环境下的特殊性质，计算起来非常困难，这也是许多加密算法安全性的基础。

**定义**

假设我们有一个有限域，比如模 $ p $（$ p $ 是一个大质数），以及一个生成元 $ g $（generator）。如果已知：$ g^x \equiv h \pmod{p} $其中：

- $ g $ 是基数（base），
- $ x $ 是离散对数，
- $ h $ 是结果，
- $ p $ 是模数。

那么，离散对数问题就是：给定 $ g $、$ h $ 和 $ p $，求解 $ x $。例如：

- 如果 $ g = 2 $，$p = 17 $，$ h = 8$，
- 我们需要找到 $x $，使得 $ 2^x \equiv 8 \pmod{17} $。

通过计算：

- $2^3 = 8 $，且 $ 8 \mod 17 = 8 $，
- 所以 $x = 3 $。

但在实际密码学中，$p $通常是一个非常大的质数（比如 256 位或更高），直接计算 $x $ 会变得极其困难，甚至在计算上是不可行的。

##### 2、DH算法

**什么是 Diffie-Hellman 算法？**

Diffie-Hellman 算法由 Whitfield Diffie 和 Martin Hellman 在 1976 年提出，是公钥密码学的开山之作。它的目标是让两个实体（比如客户端和服务器）通过公开交换信息，生成一个只有双方知道的共享密钥，而窃听者无法轻易破解。

**DH 算法的基本数学原理**

DH 算法依赖于离散对数问题，运行在一个有限域中。以下是核心要素：

1. **大质数 \( p \)**：一个大的质数，作为模数。
2. **生成元 \( g \)**：一个整数（通常较小），称为基数，满足一定的数学性质（比如 \( g \) 是 \( p \) 的原根）。
3. **私钥和公钥**：
   - 每个参与方选择一个私钥（保密的随机整数）。
   - 通过私钥和 \( g \)、\( p \) 计算出公钥（公开交换）。

离散对数问题保证了：即使攻击者知道 \( p \)、\( g \) 和公钥，也很难逆推出私钥。

**DH 算法的工作流程**

假设有两个参与方，Alice 和 Bob，他们想协商一个共享密钥。步骤如下：

1. 协商公共参数

- Alice 和 Bob 同意使用同一个大质数 \( p \) 和生成元 \( g \)。
- 这些参数是公开的，可以提前约定或通过协议传输。

2. 生成私钥和公钥

- Alice 选择一个私钥 \( a \)（一个随机大整数，保密）。
- Alice 计算她的公钥：$( A = g^a \mod p )$。
- Bob 选择一个私钥 \( b \)（另一个随机大整数，保密）。
- Bob 计算他的公钥：$( B = g^b \mod p $)。

**3. 交换公钥**

- Alice 把 \( A \) 发送给 Bob。
- Bob 把 \( B \) 发送给 Alice。
- 这些公钥是公开的，窃听者（Eve）可以截获 \( A \) 和 \( B \)。

**4. 计算共享密钥**

- Alice 用 Bob 的公钥 \( B \) 和自己的私钥 \( a \) 计算：
  $[ K = B^a \mod p ]$
- Bob 用 Alice 的公钥 \( A \) 和自己的私钥 \( b \) 计算：
  $[ K = A^b \mod p ]$
- 数学上，$( B^a \mod p = (g^b)^a \mod p = g^{ba} \mod p )$，
- 同样，$( A^b \mod p = (g^a)^b \mod p = g^{ab} \mod p )$，
- 因为$( ab = ba )$，所以双方计算出的 \( K \) 是相同的。

这个 \( K \) 就是共享密钥，只有 Alice 和 Bob 知道。

**一个简单例子**

假设 \( p = 23 \)，\( g = 5 \)：

1. Alice 选私钥 \( a = 6 \)：
   - $( A = 5^6 \mod 23 = 15625 \mod 23 = 8 )$，
   - Alice 的公钥是 \( A = 8 \)。
2. Bob 选私钥 \( b = 15 \)：
   - $( B = 5^{15} \mod 23 = 5^{15} = 30517578125 \mod 23 = 19 )$，
   - Bob 的公钥是 \( B = 19 \)。
3. 交换公钥：
   - Alice 收到 \( B = 19 \)，
   - Bob 收到 \( A = 8 \)。
4. 计算共享密钥：
   - Alice：$( K = 19^6 \mod 23 = 47045881 \mod 23 = 2 )$，
   - Bob：$( K = 8^{15} \mod 23 = 35184372088832 \mod 23 = 2 )$，
   - 共享密钥 \( K = 2 \)。

**安全性分析**

DH 算法的安全性基于离散对数问题的困难性：

- 窃听者 Eve 知道 \( p = 23 \)、\( g = 5 \)、\( A = 8 \)、\( B = 19 \)。
- 她需要从 $( A = g^a \mod p )$ 解出 \( a \)，或从 $( B = g^b \mod p )$ 解出 \( b \)。
- 这是离散对数问题，没有高效算法能在大规模 \( p \) 下快速求解。
- 即使 Eve 知道 \( A \) 和 \( B \)，直接计算 $( g^{ab} \mod p )$（即 \( K \)）也很困难（这是 Diffie-Hellman 问题，与离散对数问题等价或相关）。

##### 3、DHE算法

根据私钥生成的方式，DH 算法分为两种实现：

- static DH 算法，这个是已经被废弃了；
- DHE 算法，现在常用的；

static DH 算法里有一方的私钥是静态的，也就说每次密钥协商的时候有一方的私钥都是一样的，一般是服务器方固定，即 a 不变，客户端的私钥则是随机生成的。

于是，DH 交换密钥时就只有客户端的公钥是变化，而服务端公钥是不变的，那么随着时间延长，黑客就会截获海量的密钥协商过程的数据，因为密钥协商的过程有些数据是公开的，黑客就可以依据这些数据暴力破解出服务器的私钥，然后就可以计算出会话密钥了，于是之前截获的加密数据会被破解，所以 **static DH 算法不具备前向安全性**。

既然固定一方的私钥有被破解的风险，那么干脆就让双方的私钥在每次密钥交换通信时，都是随机生成的、临时的，这个方式也就是 DHE 算法，E 全称是 ephemeral（临时性的）。

所以，即使有个牛逼的黑客破解了某一次通信过程的私钥，其他通信过程的私钥仍然是安全的，因为**每个通信过程的私钥都是没有任何关系的，都是独立的，这样就保证了「前向安全」**。

##### 4、ECDHE算法

ECDHE 是“椭圆曲线临时 Diffie-Hellman”的缩写：

- **EC（Elliptic Curve）**：使用椭圆曲线密码学，比传统有限域 DH 更高效。
- **DH（Diffie-Hellman）**：基于离散对数问题的密钥交换机制。
- **Ephemeral（临时）**：每次会话生成新的密钥对，提供前向保密（即使长期私钥泄露，历史会话数据仍安全）。

ECDHE 的目标是让客户端和服务器通过不安全的信道协商一个共享密钥，用于加密后续通信。

小红和小明使用 ECDHE 密钥交换算法的过程：

- 双方事先确定好使用哪种椭圆曲线，和曲线上的基点 G，这两个参数都是公开的；
- 双方各自随机生成一个随机数作为**私钥d**，并与基点 G相乘得到**公钥Q**（Q = dG），此时小红的公私钥为 Q1 和 d1，小明的公私钥为 Q2 和 d2；
- 双方交换各自的公钥，最后小红计算点（x1，y1） = d1Q2，小明计算点（x2，y2） = d2Q1，由于椭圆曲线上是可以满足乘法交换和结合律，所以 d1Q2 = d1d2G = d2d1G = d2Q1 ，因此**双方的 x 坐标是一样的，所以它是共享密钥，也就是会话密钥**。

这个过程中，双方的私钥都是随机、临时生成的，都是不公开的，即使根据公开的信息（椭圆曲线、公钥、基点 G）也是很难计算出椭圆曲线上的离散对数（私钥）



##### 5、ECDHE握手过程

用 ECDHE 密钥协商算法的 TSL 握手过程，可以看到是四次握手：**使用了 ECDHE，在 TLS 第四次握手前，客户端就已经发送了加密的 HTTP 数据**，而对于 RSA 握手过程，必须要完成 TLS 四次握手，才能传输应用数据。

所以，**ECDHE 相比 RSA 握手过程省去了一个消息往返的时间**，这个有点「抢跑」的意思，它被称为是「*TLS False Start*」，跟「*TCP Fast Open*」有点像，都是在还没连接完全建立前，就发送了应用数据，这样便提高了传输的效率。

接下来，分析每一个 ECDHE 握手过程。

**（1）TLS 第一次握手（客户端发起）**

**发送内容**：

- 支持的 TLS 版本（如 TLS 1.2）。
- 支持的加密套件列表（如 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384），表明支持 ECDHE。
- 支持的椭圆曲线列表（如 NIST P-256、secp384r1），在 Supported Elliptic Curves 扩展中。
- 随机数 $Random_C $（用于后续密钥派生）。

**目的**：告诉服务器客户端的能力和偏好。

**（2）TSL第二次握手（服务器响应）**

**发送内容**：

- 选择的 TLS 版本。
- 选择的加密套件（如 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384）。
- 选择的椭圆曲线（如 P-256）。
- 随机数 $ Random_S$。

**目的**：服务器确认使用的协议参数。

接着，服务端为了证明自己的身份，发送「**Certificate**」消息，会把证书也发给客户端。

这一步就和 RSA 握手过程有很大的区别了，因为服务端选择了 ECDHE 密钥协商算法，所以会在发送完证书后，发送「**Server Key Exchange**」消息。

这个过程服务器做了三件事：

- 选择了**名为 x25519 的椭圆曲线**，选好了椭圆曲线相当于椭圆曲线基点 G 也定好了，这些都会公开给客户端；
- 生成随机数作为服务端椭圆曲线的私钥，保留到本地；
- 根据基点 G 和私钥计算出**服务端的椭圆曲线公钥**，这个会公开给客户端。

为了保证这个椭圆曲线的公钥不被第三方篡改，服务端会用 RSA 签名算法给服务端的椭圆曲线公钥做个签名。

随后，就是「**Server Hello Done**」消息，服务端跟客户端表明：“这些就是我提供的信息，打招呼完毕”。

至此，TLS 两次握手就已经完成了，目前客户端和服务端通过明文共享了这几个信息：**Client Random、Server Random 、使用的椭圆曲线、椭圆曲线基点 G、服务端椭圆曲线的公钥**，这几个信息很重要，是后续生成会话密钥的材料。

**（3）TSL第三次握手**

客户端收到了服务端的证书后，自然要校验证书是否合法，如果证书合法，那么服务端到身份就是没问题的。校验证书的过程会走证书链逐级验证，确认证书的真实性，再用证书的公钥验证签名，这样就能确认服务端的身份了，确认无误后，就可以继续往下走。

客户端会生成一个随机数作为客户端椭圆曲线的私钥，然后再根据服务端前面给的信息，生成**客户端的椭圆曲线公钥**，然后用「**Client Key Exchange**」消息发给服务端。

至此，双方都有对方的椭圆曲线公钥、自己的椭圆曲线私钥、椭圆曲线基点 G。于是，双方都就计算出点（x，y），其中 x 坐标值双方都是一样的，前面说 ECDHE 算法时候，说 x 是会话密钥，**但实际应用中，x 还不是最终的会话密钥**。

还记得 TLS 握手阶段，客户端和服务端都会生成了一个随机数传递给对方吗？

**最终的会话密钥，就是用「客户端随机数 + 服务端随机数 + x（ECDHE 算法算出的共享密钥） 」三个材料生成的**。

之所以这么麻烦，是因为 TLS 设计者不信任客户端或服务器「伪随机数」的可靠性，为了保证真正的完全随机，把三个不可靠的随机数混合起来，那么「随机」的程度就非常高了，足够让黑客计算不出最终的会话密钥，安全性更高。

算好会话密钥后，客户端会发一个「**Change Cipher Spec**」消息，告诉服务端后续改用对称算法加密通信。

接着，客户端会发「**Encrypted Handshake Message**」消息，把之前发送的数据做一个摘要，再用对称密钥加密一下，让服务端做个验证，验证下本次生成的对称密钥是否可以正常使用。

**（4）TSL第四次握手**

最后，服务端也会有一个同样的操作，发「**Change Cipher Spec**」和「**Encrypted Handshake Message**」消息，如果双方都验证加密和解密没问题，那么握手正式完成。于是，就可以正常收发加密的 HTTP 请求和响应了。

<span style="text-decoration:underline;">**RSA 和 ECDHE 握手过程的区别**</span>

| **方面**         | **RSA 握手 (TLS 1.2)**                                       | **ECDHE 握手 (TLS 1.3)**                                     |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **密钥交换机制** | 客户端生成 pre-master secret，用 RSA 公钥加密传输            | 双方生成临时 ECDHE 公钥，交换后计算共享秘密                  |
| **数学基础**     | 大整数分解困难性                                             | 椭圆曲线离散对数问题 (ECDLP)                                 |
| **消息交互**     | 2-RTT（四次消息）：<br>1. ClientHello<br>2. ServerHello + Certificate<br>3. ClientKeyExchange<br>4. Finished | 1-RTT（三次消息）：<br>1. ClientHello + KeyShare<br>2. ServerHello + KeyShare + Certificate<br>3. Finished + 数据 |
| **数据发送时机** | 必须完成四次握手后才能发送加密数据                           | 可在第三次消息附带加密数据（第四次前）                       |
| **证书作用**     | 提供 RSA 公钥直接用于加密 pre-master secret                  | 提供公钥（RSA 或 ECDSA）用于签名验证 ECDHE 参数              |
| **密钥生成**     | 客户端单向生成 pre-master secret，服务器解密                 | 双方对称计算共享秘密$  K = d_C d_S \cdot G   $               |
| **前向保密**     | 无（泄露 RSA 私钥可解密历史数据）                            | 有（临时密钥丢弃，历史数据安全）                             |
| **性能**         | RSA 加密/解密较慢，密钥长（2048 位+）                        | 椭圆曲线运算更快，密钥短（256 位+）                          |
| **随机数作用**   | 与 pre-master secret 派生会话密钥                            | 与共享秘密 $  K   $ 派生会话密钥                             |



### 3.8 

#### 2.5 HTTPS优化

HTTPS（HyperText Transfer Protocol Secure）是HTTP的安全版本，通过引入SSL/TLS加密协议，确保数据在客户端和服务器之间的传输是加密的、安全的。它解决了HTTP明文传输容易被窃听、篡改的问题，保障了隐私和数据完整性。然而，HTTPS虽然提升了安全性，却也带来了一些性能上的挑战，这就引出了优化的必要性。

这次，就从多个角度来优化 HTTPS

##### 1、分析性能损耗

既然要对 HTTPS 优化，那得清楚哪些步骤会产生性能消耗，再对症下药。

产生性能消耗的两个环节：

- 第一个环节， TLS 协议握手过程；
- 第二个环节，握手后的对称加密报文传输。

对于第二环节，现在主流的对称加密算法 AES、ChaCha20 性能都是不错的，而且一些 CPU 厂商还针对它们做了硬件级别的优化，因此这个环节的性能消耗可以说非常地小。

而第一个环节，TLS 协议握手过程不仅增加了网络延时（最长可以花费掉 2 RTT），而且握手过程中的一些步骤也会产生性能损耗，比如：

- 对于 ECDHE 密钥协商算法，握手过程中会客户端和服务端都需要临时生成椭圆曲线公私钥；
- 客户端验证证书时，会访问 CA 获取 CRL 或者 OCSP，目的是验证服务器的证书是否有被吊销；
- 双方计算 Pre-Master，也就是对称加密密钥；

##### 2、硬件优化

硬件优化的目标是加速加密相关的计算任务、降低CPU负载，并提升整体网络吞吐量。因为HTTPS涉及大量加密运算（如对称加密、非对称加密、证书验证），这些任务如果全靠通用CPU处理，会占用大量资源，尤其在高流量场景下容易成为瓶颈。硬件优化通过专用设备或芯片分担这些工作，从而提升效率。

一个好的 CPU，可以提高计算性能，因为 HTTPS 连接过程中就有大量需要计算密钥的过程，所以这样可以加速 TLS 握手过程。

另外，如果可以，应该选择可以**支持 AES-NI 特性的 CPU**，因为这种款式的 CPU 能在指令级别优化了 AES 算法，这样便加速了数据的加解密传输过程。

##### 3、软件优化

相比硬件优化，软件优化更注重通过配置调整、协议升级和代码层面的改进来提升HTTPS性能。它成本较低、灵活性强，适用于各种规模的系统。以下是HTTPS软件优化的几个关键方向，我会尽量讲得清晰且实用。

**HTTPS软件优化的核心思路**

软件优化的目标是减少TLS握手的开销、提高加密效率、优化数据传输，并确保安全性和性能的平衡。它主要依赖于协议选择、服务器配置和客户端配合，而无需额外硬件支持。

软件的优化方向可以分层两种，一个是**软件升级**，一个是**协议优化**。

- 软件升级：软件升级指的是更新或优化与HTTPS相关的软件组件，包括Web服务器软件（如Nginx、Apache）、加密库（如OpenSSL、BoringSSL）、操作系统内核等，以利用最新的功能、性能改进和安全补丁。
- 协议优化：协议优化指的是调整HTTPS使用的网络协议和加密机制，包括TLS协议版本、加密套件、会话管理等，以减少延迟、提升传输效率和安全性。

协议的优化就是对「密钥交换过程」进行优化。

**（1） 密钥交换算法优化**

TLS 1.2 版本如果使用的是 RSA 密钥交换算法，那么需要 4 次握手，也就是要花费 2 RTT，才可以进行应用数据的传输，而且 RSA 密钥交换算法不具备前向安全性。

总之使用 **RSA 密钥交换算法的 TLS 握手过程，不仅慢，而且安全性也不高**。

因此如果可以，尽量**选用 ECDHE 密钥交换**算法替换 RSA 算法，因为该算法由于支持「False Start」，它是“抢跑”的意思，客户端可以在 TLS 协议的第 3 次握手后，第 4 次握手前，发送加密的应用数据，以此将 **TLS 握手的消息往返由 2 RTT 减少到 1 RTT，而且安全性也高，具备前向安全性**。

ECDHE 算法是基于椭圆曲线实现的，不同的椭圆曲线性能也不同，应该尽量**选择 x25519 曲线**，该曲线是目前最快的椭圆曲线。

比如在 Nginx 上，可以使用 ssl_ecdh_curve 指令配置想使用的椭圆曲线，把优先使用的放在前面：

对于对称加密算法方面，如果对安全性不是特别高的要求，可以**选用 AES_128_GCM**，它比 AES_256_GCM 快一些，因为密钥的长度短一些。

**（2）TLS 升级**

当然，如果可以，直接把 TLS 1.2 升级成 TLS 1.3，TLS 1.3 大幅度简化了握手的步骤，**完成 TLS 握手只要 1 RTT**，而且安全性更高。

在 TLS 1.2 的握手中，一般是需要 4 次握手，先要通过 Client Hello （第 1 次握手）和 Server Hello（第 2 次握手） 消息协商出后续使用的加密算法，再互相交换公钥（第 3 和 第 4 次握手），然后计算出最终的会话密钥，下图的左边部分就是 TLS 1.2 的握手过程：

![image-20250308132017484](D:/interview/assets/image-20250308132017484.png)

上图的右边部分就是 TLS 1.3 的握手过程，可以发现 **TLS 1.3 把 Hello 和公钥交换这两个消息合并成了一个消息，于是这样就减少到只需 1 RTT 就能完成 TLS 握手**。

怎么合并的呢？具体的做法是，客户端在 Client Hello 消息里带上了支持的椭圆曲线，以及这些椭圆曲线对应的公钥。

服务端收到后，选定一个椭圆曲线等参数，然后返回消息时，带上服务端这边的公钥。经过这 1 个 RTT，双方手上已经有生成会话密钥的材料了，于是客户端计算出会话密钥，就可以进行应用数据的加密传输了。

而且，TLS1.3 对密码套件进行“减肥”了， **对于密钥交换算法，废除了不支持前向安全性的 RSA 和 DH 算法，只支持 ECDHE 算法**。

对于对称加密和签名算法，只支持目前最安全的几个密码套件，比如 openssl 中仅支持下面 5 种密码套件：

- TLS_AES_256_GCM_SHA384
- TLS_CHACHA20_POLY1305_SHA256
- TLS_AES_128_GCM_SHA256
- TLS_AES_128_CCM_8_SHA256
- TLS_AES_128_CCM_SHA256

之所以 TLS1.3 仅支持这么少的密码套件，是因为 TLS1.2 由于支持各种古老且不安全的密码套件，中间人可以利用降级攻击，伪造客户端的 Client Hello 消息，替换客户端支持的密码套件为一些不安全的密码套件，使得服务器被迫使用这个密码套件进行 HTTPS 连接，从而破解密文。

**（3）证书优化**

为了验证的服务器的身份，服务器会在 TLS 握手过程中，把自己的证书发给客户端，以此证明自己身份是可信的。

对于证书的优化，可以有两个方向：

- 一个是**证书传输**，
- 一个是**证书验证**；

**证书传输优化**

要让证书更便于传输，那必然是减少证书的大小，这样可以节约带宽，也能减少客户端的运算量。所以，**对于服务器的证书应该选择椭圆曲线（ECDSA）证书，而不是 RSA 证书，因为在相同安全强度下， ECC 密钥长度比 RSA 短的多**。

**证书验证优化**

客户端在验证证书时，是个复杂的过程，会走证书链逐级验证，验证的过程不仅需要「用 CA 公钥解密证书」以及「用签名算法验证证书的完整性」，而且为了知道证书是否被 CA 吊销，客户端有时还会再去访问 CA， 下载 CRL 或者 OCSP 数据，以此确认证书的有效性。

这个访问过程是 HTTP 访问，因此又会产生一系列网络通信的开销，如 DNS 查询、建立连接、收发数据等。

**CRL**

CRL 称为证书吊销列表（*Certificate Revocation List*），这个列表是由 CA 定期更新，列表内容都是被撤销信任的证书序号，如果服务器的证书在此列表，就认为证书已经失效，不在的话，则认为证书是有效的。

但是 CRL 存在两个问题：

- 第一个问题，由于 CRL 列表是由 CA 维护的，定期更新，如果一个证书刚被吊销后，客户端在更新 CRL 之前还是会信任这个证书，**实时性较差**；
- 第二个问题，**随着吊销证书的增多，列表会越来越大，下载的速度就会越慢**，下载完客户端还得遍历这么大的列表，那么就会导致客户端在校验证书这一环节的延时很大，进而拖慢了 HTTPS 连接。

OCSP

因此，现在基本都是使用 OCSP ，名为在线证书状态协议（*Online Certificate Status Protocol*）来查询证书的有效性，它的工作方式是**向 CA 发送查询请求，让 CA 返回证书的有效状态**。

不必像 CRL 方式客户端需要下载大大的列表，还要从列表查询，同时因为可以实时查询每一张证书的有效性，解决了 CRL 的实时性问题。

OCSP 需要向 CA 查询，因此也是要发生网络请求，而且还得看 CA 服务器的“脸色”，如果网络状态不好，或者 CA 服务器繁忙，也会导致客户端在校验证书这一环节的延时变大。

##### 4、会话复用

会话复用是指在HTTPS连接中，利用之前建立的TLS会话信息，避免每次连接都进行完整的TLS握手。简单来说，就是“记住上次的握手结果”，下次直接复用，省去重复的协商过程。

完整的TLS握手（Full Handshake）需要多次网络往返（RTT），包括密钥交换、证书验证等步骤，耗时较长（通常几十到几百毫秒，取决于网络延迟）。而现代网站往往涉及多个资源请求（如HTML、CSS、图片），如果每个请求都重新握手，用户体验会变差，尤其在高延迟网络中。会话复用通过缓存会话参数，让后续连接“跳过”大部分握手步骤，大幅降低延迟。

会话复用分两种：

- 第一种叫 Session ID；
- 第二种叫 Session Ticket；

**1. Session IDs（会话标识符）**

- 原理：
  - 服务器在**首次握手**时生成一个唯一的Session ID，并与会话密钥等信息绑定，存储在服务器端。
  - 客户端下次连接时发送这个Session ID，服务器找到对应的会话数据，直接恢复会话。
- 流程：
  1. 首次连接：完整握手，服务器返回Session ID。
  2. 后续连接：客户端带上Session ID，服务器验证后跳过密钥协商。
- **特点**：服务器需要维护会话缓存，占用内存。

![image-20250308133301313](D:/interview/assets/image-20250308133301313.png)

但是它有两个缺点：

- 服务器必须保持每一个客户端的会话密钥，随着客户端的增多，**服务器的内存压力也会越大**。
- 现在网站服务一般是由多台服务器通过负载均衡提供服务的，**客户端再次连接不一定会命中上次访问过的服务器**，于是还要走完整的 TLS 握手过程；



**2. Session Tickets（会话票据）**

为了解决 Session ID 的问题，就出现了 Session Ticket，**服务器不再缓存每个客户端的会话密钥，而是把缓存的工作交给了客户端**，类似于 HTTP 的 Cookie。

客户端与服务器首次建立连接时，服务器会加密「会话密钥」作为 Ticket 发给客户端，交给客户端缓存该 Ticket。

客户端再次连接服务器时，客户端会发送 Ticket，服务器解密后就可以获取上一次的会话密钥，然后验证有效期，如果没问题，就可以恢复会话了，开始加密通信。

- 原理：
  - 服务器在**首次握手**后，将会话信息（如密钥）加密成一个“票据”（Ticket），发给客户端保存。
  - 客户端下次连接时带上这个票据，服务器解密后恢复会话。
- 流程：
  1. 首次连接：完整握手，服务器生成并发送加密的Session Ticket。
  2. 后续连接：客户端提交Ticket，服务器解密后复用会话。
- **特点**：会话状态存储在客户端，减轻服务器负担，但需保护票据密钥。

![image-20250308133400340](D:/interview/assets/image-20250308133400340.png)

对于集群服务器的话，**要确保每台服务器加密 「会话密钥」的密钥是一致的**，这样客户端携带 Ticket 访问任意一台服务器时，都能恢复会话。

Session ID 和 Session Ticket **都不具备前向安全性**，因为一旦加密「会话密钥」的密钥被破解或者服务器泄漏「会话密钥」，前面劫持的通信密文都会被破解。

同时应对**重放攻击**也很困难，这里简单介绍下重放攻击工作的原理。

![image-20250308134045103](D:/interview/assets/image-20250308134045103.png)

假设 Alice 想向 Bob 证明自己的身份。 Bob 要求 Alice 的密码作为身份证明，爱丽丝应尽全力提供（可能是在经过如哈希函数的转换之后）。与此同时，Eve 窃听了对话并保留了密码（或哈希）。

交换结束后，Eve（冒充 Alice ）连接到 Bob。当被要求提供身份证明时，Eve 发送从 Bob 接受的最后一个会话中读取的 Alice 的密码（或哈希），从而授予 Eve 访问权限。

重放攻击的危险之处在于，如果中间人截获了某个客户端的 Session ID 或 Session Ticket 以及 POST 报文，而一般 POST 请求会改变数据库的数据，中间人就可以利用此截获的报文，不断向服务器发送该报文，这样就会导致数据库的数据被中间人改变了，而客户是不知情的。

避免重放攻击的方式就是需要**对会话密钥设定一个合理的过期时间**。



### 3.9

#### 2.6 HTTP/2优势

##### 1、HTTP/1.1 协议的性能问题

**队头阻塞 (Head-of-Line Blocking, HOL Blocking)**
 HTTP/1.1 一次 TCP 连接只能处理一个请求-响应对。虽然可以通过建立多个 TCP 连接（比如浏览器默认最多 6 个并行连接），但每个连接里的请求还是得排队等。前面一个请求没处理完，后面的就得干等着。比如加载一个网页，CSS、JS、图片请求都挤在一个管道里，某个慢吞吞的请求（比如大文件）会把后面全堵住，效率低下。

**连接效率低，多连接开销大**
 为了绕过队头阻塞，浏览器会开多个 TCP 连接，但这带来新问题：每次建连接都要三次握手，SSL/TLS 加密还得再握一次，时间和资源成本高。而且服务器端也得承受更多连接压力，浪费带宽和计算资源。现代网页动不动几十上百个资源，靠多连接硬撑实在不优雅。

**文本协议，解析慢且冗余**
 HTTP/1.1 是纯文本协议，Header 都是明文，重复信息多（比如每个请求都带一堆相同的 Cookie、User-Agent），没压缩，传输效率低。解析起来也慢，服务器和客户端都得逐行读，费时费力。

**不支持服务器推送**
 HTTP/1.1 是严格的“请求-响应”模式，客户端不问，服务器不答。像网页加载时，服务器明明知道你接下来要请求 CSS 或 JS，却没法主动推给你，只能等你再发请求，浪费时间。

**管道化（Pipelining）鸡肋**
 理论上 HTTP/1.1 支持管道化，可以在一个连接里连续发多个请求，不等响应就发下一个。但因为响应必须按请求顺序返回，队头阻塞问题没解决，实际用起来效果差，浏览器基本都默认关了这个功能。



##### 2、兼容HTTP/1.1

HTTP/2 出来的目的是为了改善 HTTP 的性能。协议升级有一个很重要的地方，就是要**兼容**老版本的协议，否则新协议推广起来就相当困难，所幸 HTTP/2 做到了兼容 HTTP/1.1。

那么，HTTP/2 是怎么做的呢？

**协议协商机制：ALPN 和 Upgrade 头**
 HTTP/2 并不是直接把 HTTP/1.1 扔了，而是通过协商机制让客户端和服务器动态决定用哪个版本。

- **ALPN (Application-Layer Protocol Negotiation)**：
   在 TLS 握手阶段，客户端会告诉服务器它支持的协议（比如 "h2" 表示 HTTP/2，"http/1.1" 表示老版本）。服务器如果也支持 HTTP/2，就选 "h2"，否则回退到 HTTP/1.1。这种方式特别适合 HTTPS 场景（HTTP/2 基本都跑在 TLS 上）。
- **Upgrade 头（明文 HTTP）**：
   如果是没加密的 HTTP 连接，客户端会在 HTTP/1.1 请求里加个 Upgrade: h2c 头，意思是“我想升到 HTTP/2，你行不行？”。服务器如果支持，就返回 101 Switching Protocols，然后双方切到 HTTP/2；不支持就继续用 HTTP/1.1。
- **效果**：客户端和服务器可以无缝切换，旧设备不懂 HTTP/2 也能照常用 HTTP/1.1。

**语义保持一致**
 HTTP/2 虽然底层变了（从文本协议变成二进制帧），但上层的语义跟 HTTP/1.1 没啥区别。

- 请求方法（GET、POST）、状态码（200、404）、URI、Header 的含义都一样，开发者不用改代码。
- 比如一个 HTTP/1.1 的 GET /index.html HTTP/1.1 请求，在 HTTP/2 里只是换成二进制帧传过去，服务器解析后还是干同样的事。
- **效果**：应用层逻辑不用重写，现有的 Web 程序基本能直接跑。

**Header 格式兼容性**
 HTTP/2 把 Header 从明文改成二进制并压缩（用 HPACK），但字段名字和值跟 HTTP/1.1 保持一致。比如 User-Agent、Content-Type 这些还是老样子，只是传输时更高效。客户端和服务器都能互相理解对方的 Header，哪怕版本不同。

- **效果**：老服务器看到 HTTP/2 的请求，忽略不认识的部分照样能处理。

**回退机制**
 如果服务器压根不支持 HTTP/2（比如老旧配置），客户端发现协商失败后会自动用 HTTP/1.1 通信。这种回退对用户无感，浏览器和服务器自己搞定。

- **例子**：你用 Chrome 访问一个只支持 HTTP/1.1 的网站，它会默默用老协议加载，不会崩。

**URL 和端口复用**
 HTTP/2 没改 URL 格式（还是 http:// 或 https://），默认端口也没变（HTTP 是 80，HTTPS 是 443）。不像有些新协议非要搞个新方案（比如 WebSocket 的 ws://），HTTP/2 直接沿用 HTTP/1.1 的基础设施。

- **效果**：用户和开发者感知不到协议切换，部署成本低。



##### 3、头部压缩

**HTTP/1.1 的问题**

先说 HTTP/1.1 的毛病：它的 Header 是纯文本，每次请求都得把一堆字段（比如 User-Agent、Accept、Cookie）全发过去，哪怕这些字段在多个请求里重复，也不会压缩。

- 一个网页几十个请求，可能重复发送几 KB 的 Header 数据。
- 带宽浪费严重，尤其在移动网络这种低速环境，延迟感人。

**HTTP/2 的解决方案：HPACK**

HTTP/2 引入了 **HPACK**，一个专门为头部设计的压缩算法。它把 Header 从明文改成二进制编码，还加了动态压缩机制，核心思路是“别老重复发一样的东西”。具体怎么干的：

1. 二进制编码

   - HTTP/2 把 Header 字段拆成键值对，用二进制表示，而不是 HTTP/1.1 的文本。比如 User-Agent: Mozilla/5.0... 会被编码成紧凑的字节序列，解析更快，占空间更小。

2. 静态表 (Static Table)

   - HPACK 内置了一张预定义的静态表，列出了常见字段和值的索引。它是写入到 HTTP/2 框架里的，不会变化的，静态表里共有 `61` 组，如下图：

   ![img](assets/image-20240105142818571.png)

   - 发送时直接传索引号（几字节），不用传完整字符串，省空间。

3. 动态表 (Dynamic Table)

   - 除了静态表，客户端和服务器还会维护一个动态表，记录本次连接里用过的 Header 字段和值。静态表只包含了 61 种高频出现在头部的字符串，不在静态表范围内的头部字符串就要自行构建**动态表**，它的 Index 从 `62` 起步，会在编码解码的时候随时更新。
   - 比如，第一次发送时头部中的「`User-Agent` 」字段数据有上百个字节，经过 Huffman 编码发送出去后，客户端和服务器双方都会更新自己的动态表，添加一个新的 Index 号 62。**那么在下一次发送的时候，就不用重复发这个字段的数据了，只用发 1 个字节的 Index 号就好了，因为双方都可以根据自己的动态表获取到字段的数据**。
   - 动态表会根据连接情况更新，保持高效。

4. Huffman 编码

   - 对于不在表里的字段或值，HPACK 还用 Huffman 编码进一步压缩。二进制数据里高频字符用短码，低频用长码，整体体积再缩小一圈。

**举个例子**

假设一个 HTTP/1.1 请求的 Header 是：

```
GET /index.html HTTP/1.1
Host: example.com
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64)
Cookie: session=abc123
Accept: text/html
```

- **HTTP/1.1**：全发，占几百字节。
- HTTP/2：
  - :method: GET 用静态表索引（2）。
  - :path: /index.html 用索引加少量字节。
  - Host 和 Accept 用静态表索引。
  - User-Agent 和 Cookie 第一次完整发（压缩后），存进动态表，第二次只发索引。
  - 总共可能压到几十字节。



##### 4、二进制帧

**HTTP/1.1 的问题**

HTTP/1.1 是纯文本协议，请求和响应都靠字符串拼接，像 `GET /index.html HTTP/1.1\r\nHost: example.com\r\n `这种格式。

- **解析慢**：服务器得逐行读，处理空格、换行，效率低。
- **串行化**：请求和响应得按顺序来，没法并行处理，队头阻塞严重。
- **扩展性差**：文本格式不好加新功能，改动容易破坏兼容性。

![HTTP/1 与 HTTP/2 ](assets/二进制帧.png)

HTTP/2 把响应报文划分成了两类**帧（Frame）**，图中的 HEADERS（首部）和 DATA（消息负载） 是帧的类型，也就是说一条 HTTP 响应，划分成了两类帧来传输，并且采用二进制来编码。

比如状态码 200 ，在 HTTP/1.1 是用 '2''0''0' 三个字符来表示（二进制：00110010 00110000 00110000），共用了 3 个字节

在 HTTP/2 对于状态码 200 的二进制编码是 10001000，只用了 1 字节就能表示，相比于 HTTP/1.1 节省了 2 个字节

![img](assets/h2c.png)

Header: :status: 200 OK 的编码内容为：1000 1000，那么表达的含义是什么呢？

1. 最前面的 1 标识该 Header 是静态表中已经存在的 KV。
2. 我们再回顾一下之前的静态表内容，“:status: 200 OK”其静态表编码是 8，即 1000。

因此，整体加起来就是 1000 1000。

HTTP/2二进制帧的结构如下
![image-20240105143208962](assets/image-20240105143208962.png)

| 字段          | 长度（字节） | 描述                                                         |
| ------------- | ------------ | ------------------------------------------------------------ |
| **Length**    | 3            | 帧载荷（Payload）的长度，24 位整数，不包括头部 9 字节，最大 2^24-1（16MB）。 |
| **Type**      | 1            | 帧的类型，比如 DATA、HEADERS、SETTINGS 等，决定了帧的作用。  |
| **Flags**     | 1            | 特定于帧类型的标志位，控制帧的行为，比如是否结束流。         |
| **Stream ID** | 4            | 流标识符，31 位整数（最高位保留），标识这个帧属于哪个流，0 表示连接级别。 |
| **Payload**   | 可变         | 帧的具体内容，长度由 Length 指定，不同类型帧的 Payload 格式不同。 |

帧头（Frame Header）很小，只有 9 个字节，帧开头的前 3 个字节表示帧数据（Frame Playload）的**长度**。

帧长度后面的一个字节是表示**帧的类型**，HTTP/2 总共定义了 10 种类型的帧，一般分为**数据帧**和**控制帧**两类，如下表格：

![image-20240105143150947](assets/image-20240105143150947.png)

帧类型后面的一个字节是**标志位**，可以保存 8 个标志位，用于携带简单的控制信息，比如：

- **END_HEADERS** 表示头数据结束标志，相当于 HTTP/1 里头后的空行（“\r\n”）；
- **END_Stream** 表示单方向数据发送结束，后续不会再有数据帧。
- **PRIORITY** 表示流的优先级；

帧头的最后 4 个字节是**流标识符**（Stream ID），但最高位被保留不用，只有 31 位可以使用，因此流标识符的最大值是 2^31，大约是 21 亿，它的作用是用来标识该 Frame 属于哪个 Stream，接收方可以根据这个信息从乱序的帧里找到相同 Stream ID 的帧，从而有序组装信息。

最后面就是**帧数据**了，它存放的是通过 **HPACK 算法**压缩过的 HTTP 头部和包体。

##### 5、并发传输

**HTTP/1.1 的问题**

HTTP/1.1 的传输是串行的：

- 一个 TCP 连接一次只能处理一个请求-响应对，前面的没完，后面的得等（队头阻塞）。
- 虽然可以用多连接（浏览器默认最多 6 个），但开销大（握手、资源占用），而且每个连接内部还是串行，效率不高。
- 比如加载网页时，CSS、JS、图片请求得排队，或者分散到多个连接，浪费时间和带宽。

**HTTP/2 的解决方案：多路复用**

而 HTTP/2 就很牛逼了，通过 Stream 这个设计，**多个 Stream 复用一条 TCP 连接，达到并发的效果**，解决了 HTTP/1.1 队头阻塞的问题，提高了 HTTP 传输的吞吐量。

为了理解 HTTP/2 的并发是怎样实现的，我们先来理解 HTTP/2 中的 Stream、Message、Frame 这 3 个概念。

![image-20240105143239921](assets/image-20240105143239921.png)

你可以从上图中看到：

- 1 个 TCP 连接包含一个或者多个 Stream，Stream 是 HTTP/2 并发的关键技术；
- Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成；
- Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）；

因此，我们可以得出个结论：多个 Stream 跑在一条 TCP 连接，同一个 HTTP 请求与响应是跑在同一个 Stream 中，HTTP 消息可以由多个 Frame 构成， 一个 Frame 可以由多个 TCP 报文构成。

在 HTTP/2 连接上，**不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ）**，因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息，而**同一 Stream 内部的帧必须是严格有序的**。

客户端和服务器**双方都可以建立 Stream**，因为服务端可以主动推送资源给客户端， 客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。

比如下图，Stream 1 是客户端向服务端请求的资源，属于客户端建立的 Stream，所以该 Stream 的 ID 是奇数（数字 1）；Stream 2 和 4 都是服务端主动向客户端推送的资源，属于服务端建立的 Stream，所以这两个 Stream 的 ID 是偶数（数字 2 和 4）。

![image-20240105143421889](assets/image-20240105143421889.png)

HTTP/2 通过 Stream 实现的并发，比 HTTP/1.1 通过 TCP 连接实现并发要牛逼的多，**因为当 HTTP/2 实现 100 个并发 Stream 时，只需要建立一次 TCP 连接，而 HTTP/1.1 需要建立 100 个 TCP 连接，每个 TCP 连接都要经过 TCP 握手、慢启动以及 TLS 握手过程，这些都是很耗时的。**

HTTP/2 还可以对每个 Stream 设置不同**优先级**，帧头中的「标志位」可以设置优先级，比如客户端访问 HTML/CSS 和图片资源时，希望服务器先传递 HTML/CSS，再传图片，那么就可以通过设置 Stream 的优先级来实现，以此提高用户体验。



##### 6、 服务器主动推送资源

**HTTP/1.1 的问题**

HTTP/1.1 是严格的“请求-响应”模式：

- 客户端不发请求，服务器啥也不干。
- 比如加载网页，客户端先请求 index.html，拿到后再解析，发现需要 style.css 和 script.js，又得发新请求。
- 这种往返（RTT，Round-Trip Time）浪费时间，尤其在高延迟网络（移动网、卫星网）更明显。

那 HTTP/2 的推送是怎么实现的？

HTTP/2 引入了 **PUSH_PROMISE 帧**，让服务器可以主动推送资源。核心思路是：服务器提前猜到客户端接下来要啥，直接把东西塞过去，省去额外的请求。

1. 推送的触发
   - 客户端请求一个资源（比如 index.html），用普通的 HEADERS 帧发起，流 ID 为 1。
   - 服务器知道这个页面依赖 style.css 和 script.js，决定推送它们。
2. PUSH_PROMISE 帧
   - 服务器发送 PUSH_PROMISE 帧，告诉客户端“我要推给你点东西”。
   - 帧结构：
     - **Type**：0x5（PUSH_PROMISE）。
     - **Stream ID**：关联的流（比如流 1）。
     - **Promised Stream ID**：推送资源用的新流 ID（比如 2、4，偶数）。
     - **Payload**：HPACK 编码的头部（比如 :path: /style.css）。
   - 客户端收到后，知道服务器会推啥，可以选择接受或拒绝。
3. 推送资源
   - 服务器在新流（比如流 2）上发送 HEADERS 帧（描述资源）和 DATA 帧（资源内容）。
   - 这些流跟客户端的请求流并行跑，符合多路复用机制。
   - 客户端收到后，把资源存到缓存，等需要时直接用。

![image-20240105143338707](assets/image-20240105143338707.png)



### 3.10

#### 2.7 HTTP/3

##### 1、 美中不足的 HTTP/2

HTTP/2 通过头部压缩、二进制编码、多路复用、服务器推送等新特性大幅度提升了 HTTP/1.1 的性能，而美中不足的是 HTTP/2 协议是基于 TCP 实现的，于是存在的缺陷有三个。

- 队头阻塞；
- TCP 与 TLS 的握手时延迟；
- 网络迁移需要重新连接

**（1）队头阻塞**

**HTTP/2 的改进**：

- HTTP/2 用多路复用解决了 HTTP/1.1 的管道队头阻塞，多个流（Stream）在一个 TCP 连接里并行跑。

**问题**：

- 多路复用只解决了应用层的队头阻塞，但 TCP 层面的队头阻塞还在。

- TCP 是可靠传输，要求数据按序到达。如果一个数据包丢失，整个连接得停下来重传，所有流都受影响，哪怕它们内容无关。

**例子**：

比如下图中，Stream 2 有一个 TCP 报文丢失了，那么即使收到了 Stream 3 和 Stream 4 的 TCP 报文，应用层也是无法读取读取的，相当于阻塞了 Stream 3 和 Stream 4 请求。

![img](assets/http2阻塞.jpeg)

因为 TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且有序的，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据，从 HTTP 视角看，就是请求被阻塞了。

![image-20240105144329079](assets/image-20240105144329079.png)

图中发送方发送了很多个 Packet，每个 Packet 都有自己的序号，你可以认为是 TCP 的序列号，其中 Packet 3 在网络中丢失了，即使 Packet 4-6 被接收方收到后，由于内核中的 TCP 数据不是连续的，于是接收方的应用层就无法从内核中读取到，只有等到 Packet 3 重传后，接收方的应用层才可以从内核中读取到数据，这就是 HTTP/2 的队头阻塞问题，是在 TCP 层面发生的。

**（2） TCP 与 TLS 的握手时延迟**

**问题**：

- HTTP/2 依赖 TCP，每次连接需要三次握手（1.5 RTT）。
- 如果用 TLS（HTTPS），还得加 TLS 握手（1-2 RTT），总共 2-3 RTT。

**影响**：

- 在高延迟网络（比如移动网、跨国访问），建连时间占比大，拖慢首字节时间（TTFB）。
- 短连接（比如 API 调用）频繁建连，效率更低。

**（3）丢包敏感**

**问题：**

- TCP 的拥塞控制对丢包很敏感，丢包后会缩减发送窗口（Congestion Window），降低吞吐量。
- 现代网络（尤其是无线网）丢包常见，HTTP/2 的单 TCP 连接全靠这条“独木桥”，丢包影响全局。

**例子**：

- 4G 网络丢包率 1%-2%，HTTP/2 的吞吐量可能掉 20%-30%，用户感知卡顿。



##### 2、QUIC 协议的特点

UDP 是一个简单、不可靠的传输协议，而且是 UDP 包之间是无序的，也没有依赖关系。

而且，UDP 是不需要连接的，也就不需要握手和挥手的过程，所以天然的就比 TCP 快。

当然，HTTP/3 不仅仅只是简单将传输协议替换成了 UDP，还基于 UDP 协议在「应用层」实现了 **QUIC 协议**，它具有类似 TCP 的连接管理、拥塞窗口、流量控制的网络特性，相当于将不可靠传输的 UDP 协议变成“可靠”的了，所以不用担心数据包丢失的问题。

TCP 是操作系统内核实现的，更新慢，QUIC 在应用层实现，部署灵活，迭代快。

**例子**：

- HTTP/2 想改拥塞算法，得等系统更新；QUIC 直接在 Chrome 或服务器软件里改。

QUIC 协议的优点有很多，这里举例几个，比如：

- 无队头阻塞；
- 更快的连接建立；
- 连接迁移；

**（1）无队头阻塞**

QUIC 协议也有类似 HTTP/2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。

QUIC 的多路复用是流独立的，每个流（Stream）的丢包只影响自己，不拖累其他流。

由于 QUIC 使用的传输协议是 UDP，UDP 不关心数据包的顺序，如果数据包丢失，UDP 也不关心。

不过 QUIC 协议会保证数据包的可靠性，每个数据包都有一个序号唯一标识。当某个流中的一个数据包丢失了，即使该流的其他数据包到达了，数据也无法被 HTTP/3 读取，直到 QUIC 重传丢失的报文，数据才会交给 HTTP/3。

而其他流的数据报文只要被完整接收，HTTP/3 就可以读取到数据。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。

所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。

![image-20240105144623562](assets/image-20240105144623562.png)

**（2）更快的连接建立**

- QUIC 整合了传输和加密握手，首次连接 1 RTT，后续连接可做到 0 RTT。

**怎么做到的**：

- 首次连接：客户端和服务端交换密钥和参数（1 RTT）。
- 后续连接：客户端缓存连接信息（Session Ticket），直接发加密数据，服务器验证后立即响应。

**对比 TCP+TLS**：

- HTTP/2 需要 TCP 三次握手（1.5 RTT）+ TLS 握手（1-2 RTT），总 2-3 RTT。
- QUIC 最多 1 RTT，熟悉服务器时 0 RTT。

但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是 **QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS 1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果**。

如下图右边部分，HTTP/3 当会话恢复时，有效负载数据与第一个数据包一起发送，可以做到 0-RTT：

![img](assets/d889cfd5f29129c1cb6e366b03f738cb.gif)

**（3）连接迁移**

- QUIC 用连接 ID（Connection ID）标识连接，不依赖 IP 和端口。

**怎么做到的**：

- 客户端从 Wi-Fi 切到 4G，IP 和端口变了，但连接 ID 不变，QUIC 连接不断。
- TCP 靠四元组（源 IP、源端口、目标 IP、目标端口）绑定，网络切换就得重连。

##### 3、HTTP/3协议

**（1）什么是 QPACK？**

- **定义**：QPACK 是 HTTP/3 的头部压缩协议，基于 QUIC，取代了 HTTP/2 的 HPACK。
- **目的**：减少头部数据的大小，提升传输效率，同时适配 QUIC 的独立流特性。
- **发布时间**：随 HTTP/3 标准（RFC 9114）一起发布，2022 年 6 月正式化。
- **名字来源**：QPACK 的 “Q” 代表 QUIC，表明它是为 QUIC 量身定制的。

![image-20240105144457456](assets/image-20240105144457456.png)

**为什么需要 QPACK？**

**HPACK 的问题（HTTP/2）**

HPACK 在 HTTP/2 中很成功（静态表、动态表、Huffman 编码），但有局限：

1. 动态表同步依赖 TCP
   - HPACK 的动态表（Dynamic Table）在客户端和服务器间同步更新，靠 TCP 的顺序交付。
   - 如果丢包，动态表可能不同步（比如服务器加了条目，客户端没收到），导致解码错误。
2. 队头阻塞风险
   - 动态表更新是连续的，丢包阻塞整个连接，影响所有流。
3. 不适合 QUIC
   - QUIC 的流独立传输，丢包只影响单个流，HPACK 的全局同步设计跟不上。

**QPACK 的核心特点**

**动态表是具有时序性的，如果首次出现的请求发生了丢包，后续的收到请求，对方就无法解码出 HPACK 头部，因为对方还没建立好动态表，因此后续的请求解码会阻塞到首次请求中丢失的数据包重传过来**。

HTTP/3 的 QPACK 解决了这一问题，那它是如何解决的呢？

QUIC 会有两个特殊的单向流，所谓的单向流只有一端可以发送消息，双向则指两端都可以发送消息，传输 HTTP 消息时用的是双向流，这两个单向流的用法：

- 一个叫 QPACK Encoder Stream，用于将一个字典（Key-Value）传递给对方，比如面对不属于静态表的 HTTP 请求头部，客户端可以通过这个 Stream 发送字典；
- 一个叫 QPACK Decoder Stream，用于响应对方，告诉它刚发的字典已经更新到自己的本地动态表了，后续就可以使用这个字典来编码了。

这两个特殊的单向流是用来**同步双方的动态表**，编码方收到解码方更新确认的通知后，才使用动态表编码 HTTP 头部。



### 3.11

#### 2.8 HTTP vs RPC

#####  1、从 TCP 聊起

- 要让两台电脑通信，程序员用 Socket 编程，选 TCP 或 UDP。

- TCP 可靠，普通人用它最省心，代码里 SOCK_STREAM 就是 TCP。

- 创建 Socket 后，

- TCP 是面向连接的，通信前要建立链接（三次握手）。

  服务器先 bind() + listen()，客户端 connect()，握手成功才能聊。

- 但像马总这样的高手，可能选 UDP 自己加逻辑，普通人还是 TCP 简单粗暴。



##### 2、使用纯裸 TCP 会有什么问题

八股文常背，TCP 是有三个特点，**面向连接**、**可靠**、基于**字节流**。

![TCP 是什么](assets/3fcad07ba7ae92299b32224da8583363.png)

每个特点展开都能聊一篇文章，而今天我们需要关注的是**基于字节流**这一点。

字节流可以理解为一个双向的通道里流淌的数据，这个**数据**其实就是我们常说的二进制数据，简单来说就是一大堆 **01 串**。纯裸 TCP 收发的这些 01 串之间是**没有任何边界**的，你根本不知道到哪个地方才算一条完整消息。

正因为这个没有**任何边界**的特点，所以当我们选择使用 TCP 发送"夏洛"和"特烦恼"的时候，接收端收到的就是"夏洛特烦恼"，这时候接收端没发区分你是想要表达"夏洛"+"特烦恼"还是"夏洛特"+"烦恼"。

![消息对比](assets/cd7c006cb4180bf751c4afd268ed44f0.png)

这就是所谓的**粘包问题**，之前也写过一篇专门的[文章 (opens new window)](https://xiaolincoding.com/network/3_tcp/tcp_stream.html)聊过这个问题。

说这个的目的是为了告诉大家，纯裸 TCP 是不能直接拿来用的，你需要在这个基础上加入一些**自定义的规则**，用于区分**消息边界**。

于是我们会把每条要发送的数据都包装一下，比如加入**消息头**，**消息头里写清楚一个完整的包长度是多少**，根据这个长度可以继续接收数据，截取出来后它们就是我们真正要传输的**消息体**。

![消息边界长度标志](assets/9428feed1ff22156fc136d17a129527b.png)

而这里头提到的**消息头**，还可以放各种东西，比如消息体是否被压缩过和消息体格式之类的，只要上下游都约定好了，互相都认就可以了，这就是所谓的**协议。**

每个使用 TCP 的项目都可能会定义一套类似这样的协议解析标准，他们可能**有区别，但原理都类似**。

**于是基于 TCP，就衍生了非常多的协议，比如 HTTP 和 RPC。**



##### 3、HTTP 和 RPC

我们回过头来看网络的分层图。

![四层网络协议](assets/da970d16a205fb48d6a8bea14498814d.png)

**TCP 是传输层的协议**，而基于 TCP 造出来的 HTTP 和**各类** RPC 协议，它们都只是定义了不同消息格式的**应用层协议**而已。

**HTTP** 协议（**H**yper **T**ext **T**ransfer **P**rotocol），又叫做**超文本传输协议**。我们用的比较多，平时上网在浏览器上敲个网址就能访问网页，这里用到的就是 HTTP 协议。

而 **RPC**（**R**emote **P**rocedure **C**all），又叫做**远程过程调用**。它本身并不是一个具体的协议，而是一种**调用方式**。

客户端调用 result = remoteAdd(1, 2)，底层序列化参数，发送到服务器，服务器执行后返回结果。

数据格式多是二进制（比如 Protocol Buffers）。

**那既然有 RPC 了，为什么还要有 HTTP 呢？**

**RPC 适合内部高效通信，HTTP 适合外部广泛交互，场景互补。**

现在电脑上装的各种**联网**软件，比如 xx管家，xx卫士，它们都作为**客户端（Client）需要跟服务端（Server）建立连接收发消息**，此时都会用到应用层协议，在这种 Client/Server (C/S) 架构下，它们可以使用自家造的 RPC 协议，因为它只管连自己公司的服务器就 ok 了。

但有个软件不同，**浏览器（Browser）**，不管是 Chrome 还是 IE，它们不仅要能访问自家公司的**服务器（Server）**，还需要访问其他公司的网站服务器，因此它们需要有个统一的标准，不然大家没法交流。于是，HTTP 就是那个时代用于统一 **Browser/Server (B/S)** 的协议。



#####  4、HTTP 和 RPC 有什么区别

**服务发现**

首先要向某个服务器发起请求，你得先建立连接，而建立连接的前提是，你得知道 **IP 地址和端口**。这个找到服务对应的 IP 端口的过程，其实就是**服务发现**。

在 **HTTP** 中，你知道服务的域名，就可以通过 **DNS 服务**去解析得到它背后的 IP 地址，默认 80 端口。

而 **RPC** 的话，就有些区别，一般会有专门的**中间服务**去保存服务名和IP信息，比如 **Consul 或者 Etcd，甚至是 Redis**。想要访问某个服务，就去这些中间服务去获得 IP 和端口信息。由于 DNS 也是服务发现的一种，所以也有基于 DNS 去做服务发现的组件，比如**CoreDNS**。



**底层连接形式**

可以看出服务发现这一块，两者是有些区别，但不太能分高低。

以主流的 **HTTP/1.1** 协议为例，其默认在建立底层 TCP 连接之后会一直保持这个连接（**Keep Alive**），之后的请求和响应都会复用这条连接。

而 **RPC** 协议，也跟 HTTP 类似，也是通过建立 TCP 长链接进行数据交互，但不同的地方在于，RPC 协议一般还会再建个**连接池**，在请求量大的时候，建立多条连接放在池内，要发数据的时候就从池里取一条连接出来，**用完放回去，下次再复用**，可以说非常环保。

![connection_pool](assets/ec5c8e28d3ea308c6db2ac991a12ea80.png)



**传输的内容**

**HTTP**：

- HTTP/1.1：

  - 明文文本，头（Header）和体（Body）分开。

  - 头是键值对（Key: Value），如 Content-Type: application/json。

  - 体可灵活（HTML、JSON、XML、纯文本等）。

  - 例子：

    ```text
    GET /api/users HTTP/1.1
    Host: example.com
    User-Agent: Mozilla/5.0
    Accept: application/json
    
    {"id": 1, "name": "Alice"}
    ```

    

- HTTP/2、3：

  - 二进制帧（HEADERS 帧、DATA 帧），头用 HPACK/QPACK 压缩。

  - 格式更紧凑，但仍保留头和体的结构。

  - 例子（概念化）：

    ```text
    HEADERS: :method=GET, :path=/api/users, accept=application/json
    DATA: {"id": 1, "name": "Alice"}
    ```

    

- 特点：

  - 头信息丰富（元数据多），支持 Web 的复杂需求。
  - 体格式自由，靠 Content-Type 定义。

**RPC**：

- 典型实现（如 gRPC、Thrift）：

  - 二进制序列化，通常用协议缓冲区（Protocol Buffers）或类似方案。

  - 数据是结构化的，直接映射函数参数和返回值。

  - 没有明确的头/体区分，全是紧凑的二进制 payload。

  - 例子（gRPC 用 Protobuf）：

    ```text
    message UserRequest {
      int32 id = 1;
    }
    message UserResponse {
      int32 id = 1;
      string name = 2;
    }
    // 序列化后: [01 01 02 05 41 6c 69 63 65]（id=1, name="Alice"）
    ```

    

    特点：

  - 数据紧凑，无冗余元数据。
  - 预定义 schema（IDL），传输内容固定。